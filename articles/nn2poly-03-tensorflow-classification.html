<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="nn2poly">
<title>03 - Classification example using tensorflow • nn2poly</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="03 - Classification example using tensorflow">
<meta property="og:description" content="nn2poly">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">nn2poly</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.0.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/nn2poly-01-introduction.html">01 - Introduction to nn2poly</a>
    <a class="dropdown-item" href="../articles/nn2poly-02-tensorflow-regression.html">02 - Regression example using tensorflow</a>
    <a class="dropdown-item" href="../articles/nn2poly-03-tensorflow-classification.html">03 - Classification example using tensorflow</a>
  </div>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav"></ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>03 - Classification example using tensorflow</h1>
                        <h4 data-toc-skip class="author">Pablo
Morala</h4>
            
            <h4 data-toc-skip class="date">2023-07-14</h4>
      
      
      <div class="d-none name"><code>nn2poly-03-tensorflow-classification.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="this-vignettes-goal">This vignette’s goal<a class="anchor" aria-label="anchor" href="#this-vignettes-goal"></a>
</h2>
<p>After showing how to use <code>nn2poly</code> in its default version
in <code><a href="../articles/nn2poly-01-introduction.html">vignette("nn2poly-01-introduction")</a></code>, here we will
present how to use specific methods related to <code>keras</code> and
<code>tensorflow</code> that allow for an easier and smoother use of
<code>nn2poly</code> with that deep learning framework. Furthermore, we
will sow how to impose the needed weight constraints in
<code>tensorflow</code> during training to have accurate results and
compare those results with an unconstrained neural network.</p>
<p>In this vignette we will focus on a simple classification example
using the <code>iris</code> dataset. A regression one is covered in
<code><a href="../articles/nn2poly-02-tensorflow-regression.html">vignette("nn2poly-02-tensorflow-regression")</a></code>.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://ibidat.github.io/nn2poly/">nn2poly</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://tensorflow.rstudio.com/" class="external-link">keras</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># This sets all needed seeds</span></span>
<span><span class="fu">tensorflow</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/set_random_seed.html" class="external-link">set_random_seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="simple-classification-example">Simple classification example<a class="anchor" aria-label="anchor" href="#simple-classification-example"></a>
</h2>
<div class="section level3">
<h3 id="data-preparation">Data preparation<a class="anchor" aria-label="anchor" href="#data-preparation"></a>
</h3>
<p>First we load the <code>iris</code> dataset and scale the data to the
<span class="math inline">\([-1,1]\)</span> interval:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Load the data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="va">iris</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Change response to numeric. In this case, Species was already numeric,</span></span>
<span><span class="co"># but this step is needed if it is a factor variable.</span></span>
<span><span class="va">iris</span><span class="op">$</span><span class="va">Species</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="va">iris</span><span class="op">$</span><span class="va">Species</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Define dimension p (number of predictor variables)</span></span>
<span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">iris</span><span class="op">)</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="op">-</span> <span class="fl">1</span></span>
<span></span>
<span><span class="co"># Define objective classes</span></span>
<span><span class="va">n_class</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">max</a></span><span class="op">(</span><span class="va">iris</span><span class="op">[</span>,<span class="op">(</span><span class="va">p</span><span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Move objective classes from (1:3) to (0:2), needed for tensorflow</span></span>
<span><span class="va">iris</span><span class="op">[</span>,<span class="op">(</span><span class="va">p</span><span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="va">iris</span><span class="op">[</span>,<span class="op">(</span><span class="va">p</span><span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">]</span> <span class="op">-</span> <span class="fl">1</span></span></code></pre></div>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Scale the data in the [-1,1] interval and separate train and test</span></span>
<span><span class="co"># Only the predictor variables are scaled, not the response as those will be</span></span>
<span><span class="co"># the different classes.</span></span>
<span><span class="va">iris_x</span> <span class="op">&lt;-</span> <span class="va">iris</span><span class="op">[</span>,<span class="op">-</span><span class="op">(</span><span class="va">p</span><span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="va">maxs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">iris_x</span>, <span class="fl">2</span>, <span class="va">max</span><span class="op">)</span></span>
<span><span class="va">mins</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">iris_x</span>, <span class="fl">2</span>, <span class="va">min</span><span class="op">)</span></span>
<span><span class="va">data_x_scaled</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html" class="external-link">as.data.frame</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/scale.html" class="external-link">scale</a></span><span class="op">(</span><span class="va">iris_x</span>, center <span class="op">=</span> <span class="va">mins</span> <span class="op">+</span> <span class="op">(</span><span class="va">maxs</span> <span class="op">-</span> <span class="va">mins</span><span class="op">)</span> <span class="op">/</span> <span class="fl">2</span>, scale <span class="op">=</span> <span class="op">(</span><span class="va">maxs</span> <span class="op">-</span> <span class="va">mins</span><span class="op">)</span> <span class="op">/</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">data_x_scaled</span>, <span class="va">iris</span><span class="op">[</span>,<span class="op">(</span><span class="va">p</span><span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Divide in train (0.75) and test (0.25)</span></span>
<span><span class="va">index</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fl">0.75</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">train</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">[</span><span class="va">index</span>, <span class="op">]</span></span>
<span><span class="va">test</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">[</span><span class="op">-</span><span class="va">index</span>, <span class="op">]</span></span>
<span></span>
<span><span class="va">train_x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">train</span><span class="op">[</span>,<span class="op">-</span><span class="op">(</span><span class="va">p</span><span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="va">train_y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">train</span><span class="op">[</span>,<span class="op">(</span><span class="va">p</span><span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span>
<span></span>
<span><span class="va">test_x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">test</span><span class="op">[</span>,<span class="op">-</span><span class="op">(</span><span class="va">p</span><span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="va">test_y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">test</span><span class="op">[</span>,<span class="op">(</span><span class="va">p</span><span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="original-neural-networks">Original neural networks<a class="anchor" aria-label="anchor" href="#original-neural-networks"></a>
</h3>
<p>We will build and train two different neural networks (NNs), one with
unconstrained weights (<code>nn1</code>) and another one imposing a
constraint on the weights (<code>nn2</code>).</p>
<p>Different constraints can be tested, but the suggested constraint
based on our theoretical and empirical evaluation is to use the L1 norm
equal to 1, constraining each vector of weights + bias arriving to a
neuron to satisfy that their L1 norm is equal or less than 1.</p>
<div class="section level4">
<h4 id="build-nn-1-unconstrained">Build NN 1, unconstrained<a class="anchor" aria-label="anchor" href="#build-nn-1-unconstrained"></a>
</h4>
<p>First, we build the model. Note that in this case the NN has a linear
output with the same number of neurons as the number of classes to
predict (3 species, <code>n_class</code>). Then, the linear output will
be transformed in a probability to find the most probable class but this
step is done after training. Therefore, nn2poly will be used to obtain a
polynomial that approximates this nn with linear outputs and then its
results will also be transformed in probabilities to predict the highest
probability class.</p>
<p>This NN will be built using standard tensorflow and keras practices,
in this case with a sequential keras model without any constraint on the
weights.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">nn1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model_sequential.html" class="external-link">keras_model_sequential</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="va">nn1</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html" class="external-link">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">100</span>,</span>
<span>                  activation <span class="op">=</span> <span class="st">"tanh"</span>,</span>
<span>                  input_shape <span class="op">=</span> <span class="va">p</span><span class="op">)</span></span>
<span></span>
<span><span class="va">nn1</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html" class="external-link">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">100</span>,</span>
<span>                  activation <span class="op">=</span> <span class="st">"tanh"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">nn1</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html" class="external-link">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="va">n_class</span><span class="op">)</span></span>
<span></span>
<span><span class="va">nn1</span></span>
<span><span class="co">#&gt; Model: "sequential_3"</span></span>
<span><span class="co">#&gt; ________________________________________________________________________________________________________________________</span></span>
<span><span class="co">#&gt;  Layer (type)                                         Output Shape                                    Param #           </span></span>
<span><span class="co">#&gt; ========================================================================================================================</span></span>
<span><span class="co">#&gt;  dense_8 (Dense)                                      (None, 100)                                     500               </span></span>
<span><span class="co">#&gt;  dense_9 (Dense)                                      (None, 100)                                     10100             </span></span>
<span><span class="co">#&gt;  dense_10 (Dense)                                     (None, 3)                                       303               </span></span>
<span><span class="co">#&gt; ========================================================================================================================</span></span>
<span><span class="co">#&gt; Total params: 10,903</span></span>
<span><span class="co">#&gt; Trainable params: 10,903</span></span>
<span><span class="co">#&gt; Non-trainable params: 0</span></span>
<span><span class="co">#&gt; ________________________________________________________________________________________________________________________</span></span></code></pre></div>
</div>
<div class="section level4">
<h4 id="build-nn-2-constrained">Build NN 2, constrained<a class="anchor" aria-label="anchor" href="#build-nn-2-constrained"></a>
</h4>
<p>In order to implement the desired constraints, we provide the
<code><a href="../reference/add_constraints.html">add_constraints()</a></code> function, that takes the structure of a
given NN (has to be a feed forward dense NN) and modifies its layers to
include the constraints. This is needed because default constraints
implemented in <code>keras</code> do not support to impose a constraint
at the same time on the weights and the bias and have to be combined
with a custom layer.</p>
<p>Our implementation is such that the bias on each neuron is included
in the weights vector incident on that neuron, meaning that if the
previous layer had <span class="math inline">\(h\)</span> neurons, then
the considered weight vector including the bias at a given neuron would
have dimension <span class="math inline">\(h+1\)</span>, having the bias
as it first element. Currently, L1 norm and L2 norm equal to 1 are
implemented as options.</p>
<p>Note that L1 norm equal to 1 when scaling the input data to the <span class="math inline">\([-1,1]\)</span> interval is the recommended
option.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">nn2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/add_constraints.html">add_constraints</a></span><span class="op">(</span><span class="va">nn1</span>, constraint_type <span class="op">=</span> <span class="st">"l1_norm"</span><span class="op">)</span></span>
<span><span class="va">nn2</span></span>
<span><span class="co">#&gt; Model: "sequential_4"</span></span>
<span><span class="co">#&gt; ________________________________________________________________________________________________________________________</span></span>
<span><span class="co">#&gt;  Layer (type)                                         Output Shape                                    Param #           </span></span>
<span><span class="co">#&gt; ========================================================================================================================</span></span>
<span><span class="co">#&gt;  layer__combined_l1_3 (Layer_Combined_L1)             (None, 100)                                     500               </span></span>
<span><span class="co">#&gt;  layer__combined_l1_4 (Layer_Combined_L1)             (None, 100)                                     10100             </span></span>
<span><span class="co">#&gt;  dense_11 (Dense)                                     (None, 3)                                       303               </span></span>
<span><span class="co">#&gt; ========================================================================================================================</span></span>
<span><span class="co">#&gt; Total params: 10,903</span></span>
<span><span class="co">#&gt; Trainable params: 10,903</span></span>
<span><span class="co">#&gt; Non-trainable params: 0</span></span>
<span><span class="co">#&gt; ________________________________________________________________________________________________________________________</span></span></code></pre></div>
<p>Note how the parameters and structure are the same, but the layer
type has been modified.</p>
</div>
<div class="section level4">
<h4 id="compile-and-train-both-nns">Compile and train both NNs<a class="anchor" aria-label="anchor" href="#compile-and-train-both-nns"></a>
</h4>
<p>After building both NNs, we compile and train both of them. Note
that, as constraining the weights has trade-off in the learning speed of
the NN, the <code>nn2</code> needs a higher number of epochs to properly
learn from the data.</p>
<p>In this case, we need to define a categorical crossentropy loss and
use the accuracy as the chosen metric.</p>
<p>Compile and train <code>nn1</code> the model, and visualize it:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://generics.r-lib.org/reference/compile.html" class="external-link">compile</a></span><span class="op">(</span><span class="va">nn1</span>,</span>
<span>        loss <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/loss-functions.html" class="external-link">loss_sparse_categorical_crossentropy</a></span><span class="op">(</span>from_logits <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>,</span>
<span>        optimizer <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/optimizer_adam.html" class="external-link">optimizer_adam</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>        metrics <span class="op">=</span> <span class="st">"accuracy"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">history1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span><span class="va">nn1</span>,</span>
<span>               <span class="va">train_x</span>,</span>
<span>               <span class="va">train_y</span>,</span>
<span>               verbose <span class="op">=</span> <span class="fl">0</span>,</span>
<span>               epochs <span class="op">=</span> <span class="fl">200</span>,</span>
<span>               validation_split <span class="op">=</span> <span class="fl">0.3</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">history1</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure/nn2poly-03-class-nn1-compile-1.png"></p>
<p>Compile and train <code>nn2</code> the model, and visualize it:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://generics.r-lib.org/reference/compile.html" class="external-link">compile</a></span><span class="op">(</span><span class="va">nn2</span>,</span>
<span>        loss <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/loss-functions.html" class="external-link">loss_sparse_categorical_crossentropy</a></span><span class="op">(</span>from_logits <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>,</span>
<span>        optimizer <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/optimizer_adam.html" class="external-link">optimizer_adam</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>        metrics <span class="op">=</span> <span class="st">"accuracy"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">history2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span><span class="va">nn2</span>,</span>
<span>               <span class="va">train_x</span>,</span>
<span>               <span class="va">train_y</span>,</span>
<span>               verbose <span class="op">=</span> <span class="fl">0</span>,</span>
<span>               epochs <span class="op">=</span> <span class="fl">300</span>,</span>
<span>               validation_split <span class="op">=</span> <span class="fl">0.3</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">history2</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure/nn2poly-03-class-nn2-compile-1.png"></p>
</div>
<div class="section level4">
<h4 id="obtain-the-predicionts">Obtain the predicionts<a class="anchor" aria-label="anchor" href="#obtain-the-predicionts"></a>
</h4>
<p>In this case, to asses the NNs accuracy we have to transform their
output into a probability:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">probability_model1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model_sequential.html" class="external-link">keras_model_sequential</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu">nn1</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_activation_softmax.html" class="external-link">layer_activation_softmax</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_lambda.html" class="external-link">layer_lambda</a></span><span class="op">(</span><span class="va">k_argmax</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">probability_model2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model_sequential.html" class="external-link">keras_model_sequential</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu">nn2</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_activation_softmax.html" class="external-link">layer_activation_softmax</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_lambda.html" class="external-link">layer_lambda</a></span><span class="op">(</span><span class="va">k_argmax</span><span class="op">)</span></span></code></pre></div>
<p>And predict the results with the test data for each neural network.
(We also predict and store the linear response of the NNs to be compared
later with the polynomial output)</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Obtain the predicted classes with the NN to compare them</span></span>
<span><span class="va">prediction_NN_class1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">probability_model1</span>, <span class="va">test_x</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Also, the linear output can be predicted before the probability model</span></span>
<span><span class="va">prediction_NN1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">nn1</span>, <span class="va">test_x</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Obtain the predicted classes with the NN to compare them</span></span>
<span><span class="va">prediction_NN_class2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">probability_model2</span>, <span class="va">test_x</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Also, the linear output can be predicted before the probability model</span></span>
<span><span class="va">prediction_NN2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">nn2</span>, <span class="va">test_x</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level4">
<h4 id="visualize-the-nns-results">Visualize the NNs results:<a class="anchor" aria-label="anchor" href="#visualize-the-nns-results"></a>
</h4>
<p>We can use here a confusion matrix to visualize the results, where we
can see that both NNs correctly predicts almost all of the classes in
the test data:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Create a confusion matrix</span></span>
<span><span class="va">cm1</span> <span class="op">&lt;-</span> <span class="fu">caret</span><span class="fu">::</span><span class="fu">confusionMatrix</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">as.factor</a></span><span class="op">(</span><span class="va">prediction_NN_class1</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">as.factor</a></span><span class="op">(</span><span class="va">test_y</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">cm1</span></span>
<span><span class="co">#&gt; Confusion Matrix and Statistics</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;           Reference</span></span>
<span><span class="co">#&gt; Prediction  0  1  2</span></span>
<span><span class="co">#&gt;          0 13  0  0</span></span>
<span><span class="co">#&gt;          1  0 14  2</span></span>
<span><span class="co">#&gt;          2  0  0  9</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Overall Statistics</span></span>
<span><span class="co">#&gt;                                           </span></span>
<span><span class="co">#&gt;                Accuracy : 0.9474          </span></span>
<span><span class="co">#&gt;                  95% CI : (0.8225, 0.9936)</span></span>
<span><span class="co">#&gt;     No Information Rate : 0.3684          </span></span>
<span><span class="co">#&gt;     P-Value [Acc &gt; NIR] : 7.078e-14       </span></span>
<span><span class="co">#&gt;                                           </span></span>
<span><span class="co">#&gt;                   Kappa : 0.9202          </span></span>
<span><span class="co">#&gt;                                           </span></span>
<span><span class="co">#&gt;  Mcnemar's Test P-Value : NA              </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Statistics by Class:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;                      Class: 0 Class: 1 Class: 2</span></span>
<span><span class="co">#&gt; Sensitivity            1.0000   1.0000   0.8182</span></span>
<span><span class="co">#&gt; Specificity            1.0000   0.9167   1.0000</span></span>
<span><span class="co">#&gt; Pos Pred Value         1.0000   0.8750   1.0000</span></span>
<span><span class="co">#&gt; Neg Pred Value         1.0000   1.0000   0.9310</span></span>
<span><span class="co">#&gt; Prevalence             0.3421   0.3684   0.2895</span></span>
<span><span class="co">#&gt; Detection Rate         0.3421   0.3684   0.2368</span></span>
<span><span class="co">#&gt; Detection Prevalence   0.3421   0.4211   0.2368</span></span>
<span><span class="co">#&gt; Balanced Accuracy      1.0000   0.9583   0.9091</span></span></code></pre></div>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Create a confusion matrix</span></span>
<span><span class="va">cm2</span> <span class="op">&lt;-</span> <span class="fu">caret</span><span class="fu">::</span><span class="fu">confusionMatrix</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">as.factor</a></span><span class="op">(</span><span class="va">prediction_NN_class2</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">as.factor</a></span><span class="op">(</span><span class="va">test_y</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">cm2</span></span>
<span><span class="co">#&gt; Confusion Matrix and Statistics</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;           Reference</span></span>
<span><span class="co">#&gt; Prediction  0  1  2</span></span>
<span><span class="co">#&gt;          0 13  0  0</span></span>
<span><span class="co">#&gt;          1  0 14  3</span></span>
<span><span class="co">#&gt;          2  0  0  8</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Overall Statistics</span></span>
<span><span class="co">#&gt;                                           </span></span>
<span><span class="co">#&gt;                Accuracy : 0.9211          </span></span>
<span><span class="co">#&gt;                  95% CI : (0.7862, 0.9834)</span></span>
<span><span class="co">#&gt;     No Information Rate : 0.3684          </span></span>
<span><span class="co">#&gt;     P-Value [Acc &gt; NIR] : 1.482e-12       </span></span>
<span><span class="co">#&gt;                                           </span></span>
<span><span class="co">#&gt;                   Kappa : 0.8799          </span></span>
<span><span class="co">#&gt;                                           </span></span>
<span><span class="co">#&gt;  Mcnemar's Test P-Value : NA              </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Statistics by Class:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;                      Class: 0 Class: 1 Class: 2</span></span>
<span><span class="co">#&gt; Sensitivity            1.0000   1.0000   0.7273</span></span>
<span><span class="co">#&gt; Specificity            1.0000   0.8750   1.0000</span></span>
<span><span class="co">#&gt; Pos Pred Value         1.0000   0.8235   1.0000</span></span>
<span><span class="co">#&gt; Neg Pred Value         1.0000   1.0000   0.9000</span></span>
<span><span class="co">#&gt; Prevalence             0.3421   0.3684   0.2895</span></span>
<span><span class="co">#&gt; Detection Rate         0.3421   0.3684   0.2105</span></span>
<span><span class="co">#&gt; Detection Prevalence   0.3421   0.4474   0.2105</span></span>
<span><span class="co">#&gt; Balanced Accuracy      1.0000   0.9375   0.8636</span></span></code></pre></div>
</div>
</div>
<div class="section level3">
<h3 id="using-nn2poly-to-obtain-the-polynomial">Using nn2poly to obtain the polynomial<a class="anchor" aria-label="anchor" href="#using-nn2poly-to-obtain-the-polynomial"></a>
</h3>
<p>After the NNs have been trained, we can directly call
<code>nn2poly</code> on the <code>keras</code> model. Therefore, we do
not need to build an object with weights and activation functions as in
the default case covered in
<code><a href="../articles/nn2poly-01-introduction.html">vignette("nn2poly-01-introduction")</a></code>, and can benefit from
the generic methods implemented for <code>keras</code> models.</p>
<p>The only parameters that have to be added for nn2poly to work is the
Taylor order expansion at each layer (<code>q_taylor_vector</code>),
where we will choose 8 by default on non linear layers and 1 in the last
linear layer as Taylor is not used there. (The final polynomial order
will be limited by <code>forced_max_Q=3</code>)</p>
<p>Note that in this case, as we have 3 output neurons, there will be 3
output polynomials. The polynomials will be stored in the same way as in
the regression case, in a list with labels and values, but in this case
the values will be a matrix instead of a vector, where each row will be
the polynomial obtained for each output neuron.</p>
<p>We will do this for both neural networks and compare the results:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">q_taylor_vector</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">8</span>, <span class="fl">8</span>, <span class="fl">8</span>, <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Polynomial for nn1</span></span>
<span><span class="va">final_poly1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nn2poly.html">nn2poly</a></span><span class="op">(</span>object <span class="op">=</span> <span class="va">nn1</span>,</span>
<span>                      q_taylor_vector <span class="op">=</span> <span class="va">q_taylor_vector</span>,</span>
<span>                      forced_max_Q <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Polynomial for nn2</span></span>
<span><span class="va">final_poly2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nn2poly.html">nn2poly</a></span><span class="op">(</span>object <span class="op">=</span> <span class="va">nn2</span>,</span>
<span>                      q_taylor_vector <span class="op">=</span> <span class="va">q_taylor_vector</span>,</span>
<span>                      forced_max_Q <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="obtaining-polynomial-predictions">Obtaining polynomial predictions<a class="anchor" aria-label="anchor" href="#obtaining-polynomial-predictions"></a>
</h3>
<p>As said before, the obtained polynomial represents the neural network
before including the softmax function and computing the class assigned
to each observation. Then, we need to define again a keras sequential
model that includes the class computation from the polynomial output.
This polynomial output is obtained with <code><a href="../reference/eval_poly.html">eval_poly()</a></code>, in
this case in matrix form, as the 3 polynomials are evaluated at the same
time:</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># Obtain the predicted values for the test data with our Polynomial Regression</span></span>
<span><span class="va">prediction_poly_matrix1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/eval_poly.html">eval_poly</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">test_x</span>, poly <span class="op">=</span> <span class="va">final_poly1</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Define probability model with keras fro the polynomial outputs</span></span>
<span><span class="va">probability_poly1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model_sequential.html" class="external-link">keras_model_sequential</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_activation_softmax.html" class="external-link">layer_activation_softmax</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_lambda.html" class="external-link">layer_lambda</a></span><span class="op">(</span><span class="va">k_argmax</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Class prediction with the polynomial outputs</span></span>
<span><span class="va">prediction_poly_class1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">probability_poly1</span>,<span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="va">prediction_poly_matrix1</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># Obtain the predicted values for the test data with our Polynomial Regression</span></span>
<span><span class="va">prediction_poly_matrix2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/eval_poly.html">eval_poly</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">test_x</span>, poly <span class="op">=</span> <span class="va">final_poly2</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Define probability model with keras fro the polynomial outputs</span></span>
<span><span class="va">probability_poly2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model_sequential.html" class="external-link">keras_model_sequential</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_activation_softmax.html" class="external-link">layer_activation_softmax</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_lambda.html" class="external-link">layer_lambda</a></span><span class="op">(</span><span class="va">k_argmax</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Class prediction with the polynomial outputs</span></span>
<span><span class="va">prediction_poly_class2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">probability_poly2</span>,<span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="va">prediction_poly_matrix2</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="visualizing-the-results">Visualizing the results<a class="anchor" aria-label="anchor" href="#visualizing-the-results"></a>
</h3>
<p>With the polynomial predictions, there are two options. We can
represent in a diagonal line the linear outputs obtained directly from
the polynomial and NN predictions, or compare the assigned classes after
employing the probability models. Please note here that we compare the
predictions (linear and classes) of the polynomials with the NN
predictions and not the original data, as <code>nn2poly</code>’s goal is
to faithfully represent the NN behavior independently of how well the NN
predicts.</p>
<p>First, let’s observe the confusion matrix for both NNs:</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># Confussion matrix between NN class prediction and polynomial class prediction</span></span>
<span><span class="va">cm_poly1</span> <span class="op">&lt;-</span> <span class="fu">caret</span><span class="fu">::</span><span class="fu">confusionMatrix</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">as.factor</a></span><span class="op">(</span><span class="va">prediction_NN_class1</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">as.factor</a></span><span class="op">(</span><span class="va">prediction_poly_class1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">cm_poly1</span></span>
<span><span class="co">#&gt; Confusion Matrix and Statistics</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;           Reference</span></span>
<span><span class="co">#&gt; Prediction  0  1  2</span></span>
<span><span class="co">#&gt;          0 13  0  0</span></span>
<span><span class="co">#&gt;          1  0 14  2</span></span>
<span><span class="co">#&gt;          2  0  0  9</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Overall Statistics</span></span>
<span><span class="co">#&gt;                                           </span></span>
<span><span class="co">#&gt;                Accuracy : 0.9474          </span></span>
<span><span class="co">#&gt;                  95% CI : (0.8225, 0.9936)</span></span>
<span><span class="co">#&gt;     No Information Rate : 0.3684          </span></span>
<span><span class="co">#&gt;     P-Value [Acc &gt; NIR] : 7.078e-14       </span></span>
<span><span class="co">#&gt;                                           </span></span>
<span><span class="co">#&gt;                   Kappa : 0.9202          </span></span>
<span><span class="co">#&gt;                                           </span></span>
<span><span class="co">#&gt;  Mcnemar's Test P-Value : NA              </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Statistics by Class:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;                      Class: 0 Class: 1 Class: 2</span></span>
<span><span class="co">#&gt; Sensitivity            1.0000   1.0000   0.8182</span></span>
<span><span class="co">#&gt; Specificity            1.0000   0.9167   1.0000</span></span>
<span><span class="co">#&gt; Pos Pred Value         1.0000   0.8750   1.0000</span></span>
<span><span class="co">#&gt; Neg Pred Value         1.0000   1.0000   0.9310</span></span>
<span><span class="co">#&gt; Prevalence             0.3421   0.3684   0.2895</span></span>
<span><span class="co">#&gt; Detection Rate         0.3421   0.3684   0.2368</span></span>
<span><span class="co">#&gt; Detection Prevalence   0.3421   0.4211   0.2368</span></span>
<span><span class="co">#&gt; Balanced Accuracy      1.0000   0.9583   0.9091</span></span></code></pre></div>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># Confussion matrix between NN class prediction and polynomial class prediction</span></span>
<span><span class="va">cm_poly2</span> <span class="op">&lt;-</span> <span class="fu">caret</span><span class="fu">::</span><span class="fu">confusionMatrix</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">as.factor</a></span><span class="op">(</span><span class="va">prediction_NN_class2</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">as.factor</a></span><span class="op">(</span><span class="va">prediction_poly_class2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">cm_poly2</span></span>
<span><span class="co">#&gt; Confusion Matrix and Statistics</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;           Reference</span></span>
<span><span class="co">#&gt; Prediction  0  1  2</span></span>
<span><span class="co">#&gt;          0 13  0  0</span></span>
<span><span class="co">#&gt;          1  0 17  0</span></span>
<span><span class="co">#&gt;          2  0  0  8</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Overall Statistics</span></span>
<span><span class="co">#&gt;                                      </span></span>
<span><span class="co">#&gt;                Accuracy : 1          </span></span>
<span><span class="co">#&gt;                  95% CI : (0.9075, 1)</span></span>
<span><span class="co">#&gt;     No Information Rate : 0.4474     </span></span>
<span><span class="co">#&gt;     P-Value [Acc &gt; NIR] : 5.312e-14  </span></span>
<span><span class="co">#&gt;                                      </span></span>
<span><span class="co">#&gt;                   Kappa : 1          </span></span>
<span><span class="co">#&gt;                                      </span></span>
<span><span class="co">#&gt;  Mcnemar's Test P-Value : NA         </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Statistics by Class:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;                      Class: 0 Class: 1 Class: 2</span></span>
<span><span class="co">#&gt; Sensitivity            1.0000   1.0000   1.0000</span></span>
<span><span class="co">#&gt; Specificity            1.0000   1.0000   1.0000</span></span>
<span><span class="co">#&gt; Pos Pred Value         1.0000   1.0000   1.0000</span></span>
<span><span class="co">#&gt; Neg Pred Value         1.0000   1.0000   1.0000</span></span>
<span><span class="co">#&gt; Prevalence             0.3421   0.4474   0.2105</span></span>
<span><span class="co">#&gt; Detection Rate         0.3421   0.4474   0.2105</span></span>
<span><span class="co">#&gt; Detection Prevalence   0.3421   0.4474   0.2105</span></span>
<span><span class="co">#&gt; Balanced Accuracy      1.0000   1.0000   1.0000</span></span></code></pre></div>
<p>Then, we can extract a diagonal plot for each of the polynomials
obtained for each NN, in total <span class="math inline">\(3\times
2=6\)</span> diagonal plots.</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="../reference/plot_diagonal.html">plot_diagonal</a></span><span class="op">(</span>x_axis <span class="op">=</span>  <span class="va">prediction_NN1</span><span class="op">[</span>,<span class="va">i</span><span class="op">]</span>,</span>
<span>                  y_axis <span class="op">=</span>  <span class="va">prediction_poly_matrix1</span><span class="op">[</span><span class="va">i</span>,<span class="op">]</span>,</span>
<span>                  xlab <span class="op">=</span> <span class="st">"NN prediction"</span>,</span>
<span>                  ylab <span class="op">=</span> <span class="st">"Polynomial prediction"</span><span class="op">)</span></span>
<span>        <span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p><img src="figure/nn2poly-03-class-diagonal-plot1-1.png"><img src="figure/nn2poly-03-class-diagonal-plot1-2.png"><img src="figure/nn2poly-03-class-diagonal-plot1-3.png"></p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="../reference/plot_diagonal.html">plot_diagonal</a></span><span class="op">(</span>x_axis <span class="op">=</span>  <span class="va">prediction_NN2</span><span class="op">[</span>,<span class="va">i</span><span class="op">]</span>,</span>
<span>                  y_axis <span class="op">=</span>  <span class="va">prediction_poly_matrix2</span><span class="op">[</span><span class="va">i</span>,<span class="op">]</span>,</span>
<span>                  xlab <span class="op">=</span> <span class="st">"NN prediction"</span>,</span>
<span>                  ylab <span class="op">=</span> <span class="st">"Polynomial prediction"</span><span class="op">)</span></span>
<span>        <span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p><img src="figure/nn2poly-03-class-diagonal-plot2-1.png"><img src="figure/nn2poly-03-class-diagonal-plot2-2.png"><img src="figure/nn2poly-03-class-diagonal-plot2-3.png"></p>
<p>We can observe how both polynomials obtain quite similar predictions
to their equivalent NN predictions, specially the second polynomial has
a 100% accuracy. However, when comparing the linear outputs, the
unconstrained NN presents some problems while the constrained one is
quite accurate.</p>
<p>We can also plot the <span class="math inline">\(n\)</span> most
important coefficients in absolute value to compare which variables or
interactions are more relevant in the polynomial. Note that, as data
should be scaled to the <span class="math inline">\([-1,1]\)</span>
interval, interactions of order 2 or higher would usually need a higher
absolute value than the lower order coefficients to be more
relevant.</p>
<p>In this case, we will have 3 plots for each NN again, one per
polynomial at each output neuron. In this case, the obtained
coefficients will represent the most important variables when assigning
the probability to be in each class.</p>
<p>We can see that the coefficients share some characteristics like
being positive or negative between the <code>nn1</code>and
<code>nn2</code> interpretations, as expected by how their predictions
did not differ too much.</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_n_important_coeffs.html">plot_n_important_coeffs</a></span><span class="op">(</span><span class="va">final_poly1</span>, n_important_coeffs <span class="op">=</span> <span class="fl">8</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure/nn2poly-03-class-n-important-1.png"></p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_n_important_coeffs.html">plot_n_important_coeffs</a></span><span class="op">(</span><span class="va">final_poly2</span>, n_important_coeffs <span class="op">=</span> <span class="fl">8</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure/nn2poly-03-class-n-important-2.png"></p>
<p>Finally, the problem with Taylor expansion can be checked with the
following plot, where each layer is represented with their activation
function, its Taylor expansion, the error and also the density of the
activation potentials that the activation functions receives at that
layer.</p>
<p>It can be clearly seen with the activation potentials density, in
green, that it expands over a wide range in the unconstrained NN while
the it is kept closer to zero in the constrained one, thus having a more
accurate Taylor expansion around zero.</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#Temporary parameter, should be removed or detected from object</span></span>
<span><span class="va">my_max_norm1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="st">"no_constraints"</span>,<span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">my_max_norm2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="st">"l1_norm"</span>,<span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="../reference/plot_taylor_and_activation_potentials.html">plot_taylor_and_activation_potentials</a></span><span class="op">(</span>object <span class="op">=</span> <span class="va">nn1</span>,</span>
<span>                                      data <span class="op">=</span> <span class="va">train</span>,</span>
<span>                                      q_taylor_vector <span class="op">=</span> <span class="va">q_taylor_vector</span>,</span>
<span>                                      forced_max_Q <span class="op">=</span> <span class="fl">3</span>,</span>
<span>                                      my_max_norm <span class="op">=</span> <span class="va">my_max_norm1</span><span class="op">)</span></span>
<span><span class="co">#&gt; [[1]]</span></span></code></pre></div>
<p><img src="figure/nn2poly-03-class-potentials-1.png"></p>
<pre><code><span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[2]]</span></span></code></pre>
<p><img src="figure/nn2poly-03-class-potentials-2.png"></p>
<pre><code><span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[3]]</span></span></code></pre>
<p><img src="figure/nn2poly-03-class-potentials-3.png"></p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="fu"><a href="../reference/plot_taylor_and_activation_potentials.html">plot_taylor_and_activation_potentials</a></span><span class="op">(</span>object <span class="op">=</span> <span class="va">nn2</span>,</span>
<span>                                      data <span class="op">=</span> <span class="va">train</span>,</span>
<span>                                      q_taylor_vector <span class="op">=</span> <span class="va">q_taylor_vector</span>,</span>
<span>                                      forced_max_Q <span class="op">=</span> <span class="fl">3</span>,</span>
<span>                                      my_max_norm <span class="op">=</span> <span class="va">my_max_norm2</span><span class="op">)</span></span>
<span><span class="co">#&gt; [[1]]</span></span></code></pre></div>
<p><img src="figure/nn2poly-03-class-potentials-4.png"></p>
<pre><code><span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[2]]</span></span></code></pre>
<p><img src="figure/nn2poly-03-class-potentials-5.png"></p>
<pre><code><span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[3]]</span></span></code></pre>
<p><img src="figure/nn2poly-03-class-potentials-6.png"></p>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Pablo Morala, Iñaki Ucar.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>

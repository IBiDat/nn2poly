<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="nn2poly">
<title>Supported DL frameworks • nn2poly</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Supported DL frameworks">
<meta property="og:description" content="nn2poly">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">nn2poly</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.0.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/nn2poly-01-introduction.html">Introduction to nn2poly</a>
    <a class="dropdown-item" href="../articles/nn2poly-02-supported-DL-frameworks.html">Supported DL frameworks</a>
    <a class="dropdown-item" href="../articles/nn2poly-03-classification-example.html">Classification example using tensorflow</a>
  </div>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav"></ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Supported DL frameworks</h1>
                        <h4 data-toc-skip class="author">Pablo
Morala</h4>
            
            <h4 data-toc-skip class="date">2024-01-09</h4>
      
      
      <div class="d-none name"><code>nn2poly-02-supported-DL-frameworks.Rmd</code></div>
    </div>

    
    
<p>In this vignette we will explore the supported deep learning
frameworks in <code>nn2poly</code> and how can they be used. Currently
supported frameworks are <code>keras</code>/<code>tensorflow</code> and
<code>luz</code>/<code>torch</code>. The benefit of using them is that
we provide an easy to use implementation of the weight constraints
needed during training to avoid problems in the Taylor expansion carried
out by <code>nn2poly</code>. Furthermore, models created with these
frameworks are directly supported by the <code><a href="../reference/nn2poly.html">nn2poly()</a></code>
function, allowing then to skip the need to manually create an object
with weights and activation functions as explained in
<code><a href="../articles/nn2poly-01-introduction.html">vignette("nn2poly-01-introduction")</a></code>.</p>
<p>If you are interested in having support for another deep learning
framework, please open an issue in our <a href="https://github.com/IBiDat/nn2poly" class="external-link">GitHub repo</a>!</p>
<blockquote>
<p><em>Note</em>: Using the provided constraints when training a model
increaes the number of needed epochs to converge, which is an expected
trade off between learning speed and control over the weights for easier
explainability.</p>
</blockquote>
<div class="section level2">
<h2 id="data-generation">Data generation<a class="anchor" aria-label="anchor" href="#data-generation"></a>
</h2>
<p>As our goal here is to show how to impose the needed constraints for
each framework, we will replicate the polynomial data generation from
<code><a href="../articles/nn2poly-01-introduction.html">vignette("nn2poly-01-introduction")</a></code> and solve later the
same regression problem with the different deep learning frameworks.
Refer to that vignette for more details.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://ibidat.github.io/nn2poly/">nn2poly</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">42</span><span class="op">)</span></span></code></pre></div>
<p>Create the polynomial <span class="math inline">\(4x_1 - 3
x_2x_3\)</span>:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">polynomial</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">polynomial</span><span class="op">$</span><span class="va">labels</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">3</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">polynomial</span><span class="op">$</span><span class="va">values</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">4</span>,<span class="op">-</span><span class="fl">3</span><span class="op">)</span></span></code></pre></div>
<p>Generate the data:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Define number of variables and sample size</span></span>
<span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fl">3</span></span>
<span><span class="va">n_sample</span> <span class="op">&lt;-</span> <span class="fl">500</span></span>
<span></span>
<span><span class="co"># Predictor variables</span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fl">0</span>,<span class="va">n_sample</span>,<span class="va">p</span><span class="op">)</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">p</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="va">X</span><span class="op">[</span>,<span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n_sample</span>,<span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Response variable + small error term</span></span>
<span><span class="va">Y</span> <span class="op">&lt;-</span> <span class="fu">nn2poly</span><span class="fu">:::</span><span class="fu"><a href="../reference/eval_poly.html">eval_poly</a></span><span class="op">(</span>poly <span class="op">=</span> <span class="va">polynomial</span>, newdata <span class="op">=</span> <span class="va">X</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">stats</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n_sample</span>, <span class="fl">0</span>, <span class="fl">0.1</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Store all as a data frame</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html" class="external-link">as.data.frame</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">Y</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span>
<span><span class="co">#&gt;           V1           V2         V3          Y</span></span>
<span><span class="co">#&gt; 1  1.3709584  1.029140719  2.3250585 -1.7547416</span></span>
<span><span class="co">#&gt; 2 -0.5646982  0.914774868  0.5241222 -3.7107357</span></span>
<span><span class="co">#&gt; 3  0.3631284 -0.002456267  0.9707334  1.3609395</span></span>
<span><span class="co">#&gt; 4  0.6328626  0.136009552  0.3769734  2.4608270</span></span>
<span><span class="co">#&gt; 5  0.4042683 -0.720153545 -0.9959334 -0.6141076</span></span>
<span><span class="co">#&gt; 6 -0.1061245 -0.198124330 -0.5974829 -0.7455793</span></span></code></pre></div>
<p>Scale the data to have everything in the <span class="math inline">\([-1,1]\)</span> interval and divide it in train
and test.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Data scaling to [-1,1]</span></span>
<span><span class="va">maxs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">data</span>, <span class="fl">2</span>, <span class="va">max</span><span class="op">)</span></span>
<span><span class="va">mins</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">data</span>, <span class="fl">2</span>, <span class="va">min</span><span class="op">)</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html" class="external-link">as.data.frame</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/scale.html" class="external-link">scale</a></span><span class="op">(</span><span class="va">data</span>, center <span class="op">=</span> <span class="va">mins</span> <span class="op">+</span> <span class="op">(</span><span class="va">maxs</span> <span class="op">-</span> <span class="va">mins</span><span class="op">)</span> <span class="op">/</span> <span class="fl">2</span>, scale <span class="op">=</span> <span class="op">(</span><span class="va">maxs</span> <span class="op">-</span> <span class="va">mins</span><span class="op">)</span> <span class="op">/</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Divide in train (0.75) and test (0.25)</span></span>
<span><span class="va">index</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fl">0.75</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">train</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">[</span><span class="va">index</span>, <span class="op">]</span></span>
<span><span class="va">test</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">[</span><span class="op">-</span><span class="va">index</span>, <span class="op">]</span></span>
<span></span>
<span><span class="va">train_x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">train</span><span class="op">[</span>,<span class="op">-</span><span class="op">(</span><span class="va">p</span><span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="va">train_y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">train</span><span class="op">[</span>,<span class="op">(</span><span class="va">p</span><span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span>
<span></span>
<span><span class="va">test_x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">test</span><span class="op">[</span>,<span class="op">-</span><span class="op">(</span><span class="va">p</span><span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="va">test_y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">test</span><span class="op">[</span>,<span class="op">(</span><span class="va">p</span><span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="supported-frameworks-examples">Supported frameworks examples<a class="anchor" aria-label="anchor" href="#supported-frameworks-examples"></a>
</h2>
<p>With our common data generated, we are now ready to delve into the
different deep learning frameworks. In each case we will solve the same
regression problem with the previously generated polynomial data, with
two neural networks for each framework. These neural networks will have
the same structure but one will be constrained (<code>nn_con</code>) and
the other one unconstrained (<code>nn_uncon</code>) to showcase their
differences.</p>
<div class="section level3">
<h3 id="kerastensorflow">
<code>keras</code>/<code>tensorflow</code><a class="anchor" aria-label="anchor" href="#kerastensorflow"></a>
</h3>
<p>In this section we will show how to use <code>nn2poly</code> with a
<code>keras</code> neural network and how to impose the needed weight
constraints during training.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://ibidat.github.io/nn2poly/">nn2poly</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://tensorflow.rstudio.com/" class="external-link">keras</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># This sets all needed seeds</span></span>
<span><span class="fu">tensorflow</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/set_random_seed.html" class="external-link">set_random_seed</a></span><span class="op">(</span><span class="fl">42</span><span class="op">)</span></span></code></pre></div>
<div class="section level4">
<h4 id="model-definition">Model definition<a class="anchor" aria-label="anchor" href="#model-definition"></a>
</h4>
<p>First of all we will set the structure of our neural networks using a
sequential model in <code>keras</code>. This following function will be
used to create both the constrained and unconstrained neural networks in
the <code>keras</code> example.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">keras_model</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu">tensorflow</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/set_random_seed.html" class="external-link">set_random_seed</a></span><span class="op">(</span><span class="fl">42</span><span class="op">)</span></span>
<span></span>
<span>  <span class="va">nn</span> <span class="op">&lt;-</span> <span class="fu">keras</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model_sequential.html" class="external-link">keras_model_sequential</a></span><span class="op">(</span><span class="op">)</span></span>
<span>  <span class="va">nn</span> <span class="op">&lt;-</span> <span class="fu">keras</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html" class="external-link">layer_dense</a></span><span class="op">(</span><span class="va">nn</span>, units <span class="op">=</span> <span class="fl">100</span>, activation <span class="op">=</span> <span class="st">"tanh"</span>, input_shape <span class="op">=</span> <span class="va">p</span><span class="op">)</span></span>
<span>  <span class="va">nn</span> <span class="op">&lt;-</span> <span class="fu">keras</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html" class="external-link">layer_dense</a></span><span class="op">(</span><span class="va">nn</span>, units <span class="op">=</span> <span class="fl">100</span>, activation <span class="op">=</span> <span class="st">"tanh"</span><span class="op">)</span></span>
<span>  <span class="va">nn</span> <span class="op">&lt;-</span> <span class="fu">keras</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html" class="external-link">layer_dense</a></span><span class="op">(</span><span class="va">nn</span>, units <span class="op">=</span> <span class="fl">100</span>, activation <span class="op">=</span> <span class="st">"tanh"</span><span class="op">)</span></span>
<span>  <span class="va">nn</span> <span class="op">&lt;-</span> <span class="fu">keras</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html" class="external-link">layer_dense</a></span><span class="op">(</span><span class="va">nn</span>, units <span class="op">=</span> <span class="fl">1</span>, activation <span class="op">=</span> <span class="st">"linear"</span><span class="op">)</span></span>
<span></span>
<span>  <span class="va">nn</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>Now we define both NNs. The only needed step to impose our
implemented weight constraints on a <code>keras</code> model is to use
the function <code><a href="../reference/add_constraints.html">add_constraints()</a></code> and then train it as
usually. The constraints currently accept two possible types,
<code>"l1_norm"</code> and <code>"l2_norm"</code>. In both cases, the
norm for each weight vector (including the bias) incident on a neuron
will be constrained to be less or equal than 1. Using data scaled to the
<span class="math inline">\([-1,1]\)</span> interval, the l1-norm is the
one that guarantees best results.</p>
<p>Also, it is important to note that the weight constraints are imposed
on all layers except for the last one, which is expected to be linear
and not need a Taylor expansion.</p>
<blockquote>
<p><em>Note</em>: Our implementation differs sligthly from the
constraints provided by <code>keras</code> because in our implementation
we join the bias with the rest of the weights while <code>keras</code>
default constraints allow only for bias or kernel constraints. Our
implementation uses a custom callback that is applied at the end of each
batch.</p>
</blockquote>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">nn_uncon</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model.html" class="external-link">keras_model</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="va">nn_con</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model.html" class="external-link">keras_model</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">nn_con</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/add_constraints.html">add_constraints</a></span><span class="op">(</span><span class="va">nn_con</span>, constraint_type <span class="op">=</span> <span class="st">"l1_norm"</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level4">
<h4 id="training">Training<a class="anchor" aria-label="anchor" href="#training"></a>
</h4>
<p>Now we can compile and train both NNs using standard the
<code>keras</code> approach. Note that we have to increase the number of
needed epochs with the constrained NN to learn properly.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://generics.r-lib.org/reference/compile.html" class="external-link">compile</a></span><span class="op">(</span><span class="va">nn_uncon</span>,</span>
<span>        loss <span class="op">=</span> <span class="st">"mse"</span>,</span>
<span>        optimizer <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/optimizer_adam.html" class="external-link">optimizer_adam</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>        metrics <span class="op">=</span> <span class="st">"mse"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">history1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span><span class="va">nn_uncon</span>,</span>
<span>               <span class="va">train_x</span>,</span>
<span>               <span class="va">train_y</span>,</span>
<span>               verbose <span class="op">=</span> <span class="fl">0</span>,</span>
<span>               epochs <span class="op">=</span> <span class="fl">150</span>,</span>
<span>               batch_size <span class="op">=</span> <span class="fl">50</span>,</span>
<span>               validation_split <span class="op">=</span> <span class="fl">0.2</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">history1</span><span class="op">)</span></span></code></pre></div>
<p><img src="includes/nn2poly-02-keras-nn_uncon-train-1.png"></p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://generics.r-lib.org/reference/compile.html" class="external-link">compile</a></span><span class="op">(</span><span class="va">nn_con</span>,</span>
<span>        loss <span class="op">=</span> <span class="st">"mse"</span>,</span>
<span>        optimizer <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/optimizer_adam.html" class="external-link">optimizer_adam</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>        metrics <span class="op">=</span> <span class="st">"mse"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">history2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span><span class="va">nn_con</span>,</span>
<span>               <span class="va">train_x</span>,</span>
<span>               <span class="va">train_y</span>,</span>
<span>               verbose <span class="op">=</span> <span class="fl">0</span>,</span>
<span>               epochs <span class="op">=</span> <span class="fl">700</span>,</span>
<span>               batch_size <span class="op">=</span> <span class="fl">50</span>,</span>
<span>               validation_split <span class="op">=</span> <span class="fl">0.2</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">history2</span><span class="op">)</span></span></code></pre></div>
<p><img src="includes/nn2poly-02-keras-nn_con-train-1.png"></p>
</div>
<div class="section level4">
<h4 id="nn-predictions">NN predictions<a class="anchor" aria-label="anchor" href="#nn-predictions"></a>
</h4>
<p>We can visualize the NN predictions vs the original Y values for both
neural networks and observe how both of them provide accurate
predictions (the values fall near the “perfect” diagonal red line).</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Obtain the predicted values with the NN to compare them</span></span>
<span><span class="va">prediction_nn_uncon</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">nn_uncon</span>, <span class="va">test_x</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Diagonal plot implemented in the package to quickly visualize and compare predictions</span></span>
<span><span class="fu"><a href="../reference/plot_diagonal.html">plot_diagonal</a></span><span class="op">(</span>x_axis <span class="op">=</span>  <span class="va">prediction_nn_uncon</span>, y_axis <span class="op">=</span>  <span class="va">test_y</span>, xlab <span class="op">=</span> <span class="st">"Unconstrained NN prediction"</span>, ylab <span class="op">=</span> <span class="st">"Original Y"</span><span class="op">)</span></span></code></pre></div>
<p><img src="includes/nn2poly-02-keras-comparison-y-nn_uncon-1.png"></p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Obtain the predicted values with the NN to compare them</span></span>
<span><span class="va">prediction_nn_con</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">nn_con</span>, <span class="va">test_x</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Diagonal plot implemented in the package to quickly visualize and compare predictions</span></span>
<span><span class="fu"><a href="../reference/plot_diagonal.html">plot_diagonal</a></span><span class="op">(</span>x_axis <span class="op">=</span>  <span class="va">prediction_nn_con</span>, y_axis <span class="op">=</span>  <span class="va">test_y</span>, xlab <span class="op">=</span> <span class="st">"Constrained NN prediction"</span>, ylab <span class="op">=</span> <span class="st">"Original Y"</span><span class="op">)</span></span></code></pre></div>
<p><img src="includes/nn2poly-02-keras-comparison-y-nn_con-1.png"></p>
</div>
<div class="section level4">
<h4 id="using-nn2poly">Using nn2poly<a class="anchor" aria-label="anchor" href="#using-nn2poly"></a>
</h4>
<p>After the NNs have been trained, we can directly call
<code>nn2poly</code> on the <code>keras</code> model.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Polynomial for nn_uncon</span></span>
<span><span class="va">final_poly_uncon</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nn2poly.html">nn2poly</a></span><span class="op">(</span>object <span class="op">=</span> <span class="va">nn_uncon</span>,</span>
<span>                      max_order <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Polynomial for nn_con</span></span>
<span><span class="va">final_poly_con</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nn2poly.html">nn2poly</a></span><span class="op">(</span>object <span class="op">=</span> <span class="va">nn_con</span>,</span>
<span>                      max_order <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span></code></pre></div>
<p>We can visualize the polynomial predictions versus NN predictions</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># Obtain the predicted values for the test data with our two polynomials</span></span>
<span><span class="va">prediction_poly_uncon</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span>object <span class="op">=</span> <span class="va">final_poly_uncon</span>, newdata <span class="op">=</span> <span class="va">test_x</span><span class="op">)</span></span>
<span><span class="va">prediction_poly_con</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span>object <span class="op">=</span> <span class="va">final_poly_con</span>, newdata <span class="op">=</span> <span class="va">test_x</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="../reference/plot_diagonal.html">plot_diagonal</a></span><span class="op">(</span>x_axis <span class="op">=</span>  <span class="va">prediction_nn_uncon</span>, y_axis <span class="op">=</span>  <span class="va">prediction_poly_uncon</span>, xlab <span class="op">=</span> <span class="st">"NN prediction"</span>, ylab <span class="op">=</span> <span class="st">"Polynomial prediction"</span><span class="op">)</span> <span class="op">+</span> <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">ggtitle</a></span><span class="op">(</span><span class="st">"Polynomial for nn_uncon"</span><span class="op">)</span></span></code></pre></div>
<p><img src="includes/nn2poly-02-keras-polynomial-prediction-1.png"></p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="fu"><a href="../reference/plot_diagonal.html">plot_diagonal</a></span><span class="op">(</span>x_axis <span class="op">=</span>  <span class="va">prediction_nn_con</span>, y_axis <span class="op">=</span>  <span class="va">prediction_poly_con</span>, xlab <span class="op">=</span> <span class="st">"NN prediction"</span>, ylab <span class="op">=</span> <span class="st">"Polynomial prediction"</span><span class="op">)</span> <span class="op">+</span> <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">ggtitle</a></span><span class="op">(</span><span class="st">"Polynomial for nn_con"</span><span class="op">)</span></span></code></pre></div>
<p><img src="includes/nn2poly-02-keras-polynomial-prediction-2.png"></p>
<p>We can clearly see how the constrained NN allows to obtain a close
approximation with <code>nn2poly</code> while the polynomial obtained
for the unconstrained one is not a good representation.</p>
<p>We can also represent the obtained polynomial coefficients and
observe how the constrained case clearly has terms <code>2,3</code> and
<code>1</code> with the same sign as the original polynomial while the
rest are close to 0.</p>
<blockquote>
<p><em>Note</em>: The coefficients values are not in the same scale as
the original polynomial due to the fact that we have scaled all the data
before training, even the response variable Y. Furthermore, as data has
been scaled to the <span class="math inline">\([-1,1]\)</span> interval,
interactions of order 2 or higher would usually need a higher absolute
value than the lower order coefficients to be more relevant</p>
</blockquote>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_n_important_coeffs.html">plot_n_important_coeffs</a></span><span class="op">(</span><span class="va">final_poly_uncon</span>, n_important_coeffs <span class="op">=</span> <span class="fl">8</span><span class="op">)</span></span></code></pre></div>
<p><img src="includes/nn2poly-02-keras-n-important-1.png"></p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_n_important_coeffs.html">plot_n_important_coeffs</a></span><span class="op">(</span><span class="va">final_poly_con</span>, n_important_coeffs <span class="op">=</span> <span class="fl">8</span><span class="op">)</span></span></code></pre></div>
<p><img src="includes/nn2poly-02-keras-n-important-2.png"></p>
</div>
</div>
<div class="section level3">
<h3 id="luztorch">
<code>luz</code>/<code>torch</code><a class="anchor" aria-label="anchor" href="#luztorch"></a>
</h3>
<p>In this section we will show how to use <code>nn2poly</code> with a
<code>torch</code> neural network, built with its higher level API
<code>luz</code>, and how to impose the needed weight constraints during
training. Furthermore, we will explain how to use
<code><a href="../reference/luz_model_sequential.html">luz_model_sequential()</a></code>, a helper needed to create a
<code>torch</code> model in an adequate manner so that it can be easily
recognized by <code>nn2poly</code>.</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://torch.mlverse.org/docs" class="external-link">torch</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://mlverse.github.io/luz/" class="external-link">luz</a></span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">42</span><span class="op">)</span></span></code></pre></div>
<div class="section level4">
<h4 id="data-loader-for-torch">Data loader for <code>torch</code><a class="anchor" aria-label="anchor" href="#data-loader-for-torch"></a>
</h4>
<p>In this framework, we need to manipulate a bit our data to use it as
input for a <code>torch</code> model. This can be done dividing our
<code>train_x</code> data intro only train and validation matrices and
using <code><a href="https://mlverse.github.io/luz/reference/as_dataloader.html" class="external-link">luz::as_dataloader()</a></code></p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Divide in only train and validation</span></span>
<span><span class="va">all_indices</span>   <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">train_x</span><span class="op">)</span></span>
<span><span class="va">only_train_indices</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="va">all_indices</span>, size <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">train_x</span><span class="op">)</span><span class="op">)</span> <span class="op">*</span> <span class="fl">0.8</span><span class="op">)</span></span>
<span><span class="va">val_indices</span>   <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sets.html" class="external-link">setdiff</a></span><span class="op">(</span><span class="va">all_indices</span>, <span class="va">only_train_indices</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Create lists with x and y values to feed luz::as_dataloader()</span></span>
<span><span class="va">only_train_x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">train_x</span><span class="op">[</span><span class="va">only_train_indices</span>,<span class="op">]</span><span class="op">)</span></span>
<span><span class="va">only_train_y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">train_y</span><span class="op">[</span><span class="va">only_train_indices</span>,<span class="op">]</span><span class="op">)</span></span>
<span><span class="va">val_x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">train_x</span><span class="op">[</span><span class="va">val_indices</span>,<span class="op">]</span><span class="op">)</span></span>
<span><span class="va">val_y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">train_y</span><span class="op">[</span><span class="va">val_indices</span>,<span class="op">]</span><span class="op">)</span></span>
<span></span>
<span><span class="va">only_train_list</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">only_train_x</span>, y <span class="op">=</span> <span class="va">only_train_y</span><span class="op">)</span></span>
<span><span class="va">val_list</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">val_x</span>, y <span class="op">=</span> <span class="va">val_y</span><span class="op">)</span></span>
<span></span>
<span><span class="va">torch_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>  train <span class="op">=</span> <span class="fu">luz</span><span class="fu">::</span><span class="fu"><a href="https://mlverse.github.io/luz/reference/as_dataloader.html" class="external-link">as_dataloader</a></span><span class="op">(</span><span class="va">only_train_list</span>, batch_size <span class="op">=</span> <span class="fl">50</span>, shuffle <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>,</span>
<span>  valid <span class="op">=</span> <span class="fu">luz</span><span class="fu">::</span><span class="fu"><a href="https://mlverse.github.io/luz/reference/as_dataloader.html" class="external-link">as_dataloader</a></span><span class="op">(</span><span class="va">val_list</span>, batch_size <span class="op">=</span> <span class="fl">50</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level4">
<h4 id="model-definition-1">Model definition<a class="anchor" aria-label="anchor" href="#model-definition-1"></a>
</h4>
<p>Now we will set the structure of our neural networks using a
sequential model in <code>torch</code>. To do so we have implemented the
helper <code><a href="../reference/luz_model_sequential.html">luz_model_sequential()</a></code>, which lets the user stack
linear layers in a similar way as <code>keras</code> and allows
<code><a href="../reference/nn2poly.html">nn2poly()</a></code> to be directly used in the model without the need
to extract weights and activation functions manually as in the default
example of <code><a href="../articles/nn2poly-01-introduction.html">vignette("nn2poly-01-introduction")</a></code>.</p>
<p>This following function will be used to create both the constrained
and unconstrained neural networks in the <code>torch</code> example.</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">luz_nn</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/torch/man/torch_manual_seed.html" class="external-link">torch_manual_seed</a></span><span class="op">(</span><span class="fl">42</span><span class="op">)</span></span>
<span></span>
<span>  <span class="fu"><a href="../reference/luz_model_sequential.html">luz_model_sequential</a></span><span class="op">(</span></span>
<span>    <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/torch/man/nn_linear.html" class="external-link">nn_linear</a></span><span class="op">(</span><span class="va">p</span>,<span class="fl">100</span><span class="op">)</span>,</span>
<span>    <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/torch/man/nn_tanh.html" class="external-link">nn_tanh</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/torch/man/nn_linear.html" class="external-link">nn_linear</a></span><span class="op">(</span><span class="fl">100</span>,<span class="fl">100</span><span class="op">)</span>,</span>
<span>    <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/torch/man/nn_tanh.html" class="external-link">nn_tanh</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/torch/man/nn_linear.html" class="external-link">nn_linear</a></span><span class="op">(</span><span class="fl">100</span>,<span class="fl">100</span><span class="op">)</span>,</span>
<span>    <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/torch/man/nn_tanh.html" class="external-link">nn_tanh</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/torch/man/nn_linear.html" class="external-link">nn_linear</a></span><span class="op">(</span><span class="fl">100</span>,<span class="fl">1</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>Now we define both NNs. In this case, differing from the
<code>keras</code> example, we will impose the constraints later to
follow the same approach as in <code>luz</code> documentation. However,
the use of <code><a href="../reference/add_constraints.html">add_constraints()</a></code> is analogous.</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">nn_uncon</span> <span class="op">&lt;-</span> <span class="fu">luz_nn</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">nn_con</span> <span class="op">&lt;-</span> <span class="fu">luz_nn</span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level4">
<h4 id="training-1">Training<a class="anchor" aria-label="anchor" href="#training-1"></a>
</h4>
<p>First we train the unconstrained NN using ans standard
<code>luz</code> approach.</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fitted_uncon</span> <span class="op">&lt;-</span> <span class="va">nn_uncon</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>    <span class="fu">luz</span><span class="fu">::</span><span class="fu"><a href="https://mlverse.github.io/luz/reference/setup.html" class="external-link">setup</a></span><span class="op">(</span></span>
<span>      loss <span class="op">=</span> <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/torch/man/nn_mse_loss.html" class="external-link">nn_mse_loss</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>      optimizer <span class="op">=</span> <span class="fu">torch</span><span class="fu">::</span><span class="va"><a href="https://rdrr.io/pkg/torch/man/optim_adam.html" class="external-link">optim_adam</a></span>,</span>
<span>      metrics <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>        <span class="fu">luz</span><span class="fu">::</span><span class="fu"><a href="https://mlverse.github.io/luz/reference/luz_metric_mse.html" class="external-link">luz_metric_mse</a></span><span class="op">(</span><span class="op">)</span></span>
<span>      <span class="op">)</span></span>
<span>    <span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>    <span class="fu">luz</span><span class="fu">::</span><span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span><span class="va">torch_data</span><span class="op">$</span><span class="va">train</span>, epochs <span class="op">=</span> <span class="fl">50</span>, valid_data <span class="op">=</span> <span class="va">torch_data</span><span class="op">$</span><span class="va">valid</span><span class="op">)</span></span>
<span></span>
<span><span class="va">fitted_uncon</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p><img src="includes/nn2poly-02-torch-nn_uncon-train-1.png"></p>
<p>Then, we train the constrained NN by using the function function
<code><a href="../reference/add_constraints.html">add_constraints()</a></code> before calling <code><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit()</a></code>. The
constraints currently accept two possible types, <code>"l1_norm"</code>
and <code>"l2_norm"</code>. In both cases, the norm for each weight
vector (including the bias) incident on a neuron will be constrained to
be less or equal than 1. Using data scaled to the <span class="math inline">\([-1,1]\)</span> interval, the l1-norm is the one
that guarantees best results.</p>
<p>Also, it is important to note that the weight constraints are imposed
on all layers except for the last one, which is expected to be linear
and not need a Taylor expansion.</p>
<p>Note that we have to increase the number of needed epochs with the
constrained NN to learn properly.</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fitted_con</span> <span class="op">&lt;-</span> <span class="va">nn_con</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu">luz</span><span class="fu">::</span><span class="fu"><a href="https://mlverse.github.io/luz/reference/setup.html" class="external-link">setup</a></span><span class="op">(</span></span>
<span>    loss <span class="op">=</span> <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/torch/man/nn_mse_loss.html" class="external-link">nn_mse_loss</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    optimizer <span class="op">=</span> <span class="fu">torch</span><span class="fu">::</span><span class="va"><a href="https://rdrr.io/pkg/torch/man/optim_adam.html" class="external-link">optim_adam</a></span>,</span>
<span>  <span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="../reference/add_constraints.html">add_constraints</a></span><span class="op">(</span><span class="st">"l1_norm"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span><span class="va">torch_data</span><span class="op">$</span><span class="va">train</span>, epochs <span class="op">=</span> <span class="fl">700</span>, valid_data <span class="op">=</span> <span class="va">torch_data</span><span class="op">$</span><span class="va">valid</span><span class="op">)</span></span>
<span></span>
<span><span class="va">fitted_con</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p><img src="includes/nn2poly-02-torch-nn_con-train-1.png"></p>
<blockquote>
<p><em>Note</em>: Our implementation uses a custom callback that is
applied at the end of each batch.</p>
</blockquote>
</div>
<div class="section level4">
<h4 id="nn-predictions-1">NN predictions<a class="anchor" aria-label="anchor" href="#nn-predictions-1"></a>
</h4>
<p>We can visualize the NN predictions vs the original Y values for both
neural networks and observe how both of them provide accurate
predictions (the values fall near the “perfect” diagonal red line).</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Obtain the predicted values with the NN to compare them</span></span>
<span><span class="va">prediction_NN_uncon</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/array.html" class="external-link">as.array</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fitted_uncon</span>, <span class="va">test_x</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Diagonal plot implemented in the package to quickly visualize and compare predictions</span></span>
<span><span class="fu"><a href="../reference/plot_diagonal.html">plot_diagonal</a></span><span class="op">(</span>x_axis <span class="op">=</span>  <span class="va">prediction_NN_uncon</span>, y_axis <span class="op">=</span>  <span class="va">test_y</span>, xlab <span class="op">=</span> <span class="st">"Unconstrained NN prediction"</span>, ylab <span class="op">=</span> <span class="st">"Original Y"</span><span class="op">)</span></span></code></pre></div>
<p><img src="includes/nn2poly-02-torch-comparison-y-nn_uncon-1.png"></p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Obtain the predicted values with the NN to compare them</span></span>
<span><span class="va">prediction_NN_con</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/array.html" class="external-link">as.array</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fitted_con</span>, <span class="va">test_x</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Diagonal plot implemented in the package to quickly visualize and compare predictions</span></span>
<span><span class="fu"><a href="../reference/plot_diagonal.html">plot_diagonal</a></span><span class="op">(</span>x_axis <span class="op">=</span>  <span class="va">prediction_NN_con</span>, y_axis <span class="op">=</span>  <span class="va">test_y</span>, xlab <span class="op">=</span> <span class="st">"Constrained NN prediction"</span>, ylab <span class="op">=</span> <span class="st">"Original Y"</span><span class="op">)</span></span></code></pre></div>
<p><img src="includes/nn2poly-02-torch-comparison-y-nn_con-1.png"></p>
</div>
<div class="section level4">
<h4 id="using-nn2poly-1">Using nn2poly<a class="anchor" aria-label="anchor" href="#using-nn2poly-1"></a>
</h4>
<p>After the NNs have been trained, we can directly call
<code>nn2poly</code> on the <code>luz</code> model.</p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Polynomial for nn_uncon</span></span>
<span><span class="va">final_poly_uncon</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nn2poly.html">nn2poly</a></span><span class="op">(</span>object <span class="op">=</span> <span class="va">fitted_uncon</span>,</span>
<span>                      max_order <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Polynomial for nn_con</span></span>
<span><span class="va">final_poly_con</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nn2poly.html">nn2poly</a></span><span class="op">(</span>object <span class="op">=</span> <span class="va">fitted_con</span>,</span>
<span>                      max_order <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span></code></pre></div>
<p>We can visualize the polynomial predictions versus NN predictions</p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># Obtain the predicted values for the test data with our two polynomials</span></span>
<span><span class="va">prediction_poly_uncon</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span>object <span class="op">=</span> <span class="va">final_poly_uncon</span>, newdata <span class="op">=</span> <span class="va">test_x</span><span class="op">)</span></span>
<span><span class="va">prediction_poly_con</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span>object <span class="op">=</span> <span class="va">final_poly_con</span>, newdata <span class="op">=</span> <span class="va">test_x</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="../reference/plot_diagonal.html">plot_diagonal</a></span><span class="op">(</span>x_axis <span class="op">=</span>  <span class="va">prediction_nn_uncon</span>, y_axis <span class="op">=</span>  <span class="va">prediction_poly_uncon</span>, xlab <span class="op">=</span> <span class="st">"NN prediction"</span>, ylab <span class="op">=</span> <span class="st">"Polynomial prediction"</span><span class="op">)</span> <span class="op">+</span> <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">ggtitle</a></span><span class="op">(</span><span class="st">"Polynomial for nn_uncon"</span><span class="op">)</span></span></code></pre></div>
<p><img src="includes/nn2poly-02-reg-polynomial-prediction-1.png"></p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="fu"><a href="../reference/plot_diagonal.html">plot_diagonal</a></span><span class="op">(</span>x_axis <span class="op">=</span>  <span class="va">prediction_nn_con</span>, y_axis <span class="op">=</span>  <span class="va">prediction_poly_con</span>, xlab <span class="op">=</span> <span class="st">"NN prediction"</span>, ylab <span class="op">=</span> <span class="st">"Polynomial prediction"</span><span class="op">)</span> <span class="op">+</span> <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">ggtitle</a></span><span class="op">(</span><span class="st">"Polynomial for nn_con"</span><span class="op">)</span></span></code></pre></div>
<p><img src="includes/nn2poly-02-reg-polynomial-prediction-2.png"></p>
<p>We can clearly see how the constrained NN allows to obtain a close
approximation with <code>nn2poly</code> while the polynomial obtained
for the unconstrained one is not a good representation.</p>
<p>We can also represent the obtained polynomial coefficients and
observe how the constrained case clearly has terms <code>2,3</code> and
<code>1</code> with the same sign as the original polynomial while the
rest are close to 0.</p>
<blockquote>
<p><em>Note</em>: The coefficients values are not in the same scale as
the original polynomial due to the fact that we have scaled all the data
before training, even the response variable Y. Furthermore, as data has
been scaled to the <span class="math inline">\([-1,1]\)</span> interval,
interactions of order 2 or higher would usually need a higher absolute
value than the lower order coefficients to be more relevant</p>
</blockquote>
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_n_important_coeffs.html">plot_n_important_coeffs</a></span><span class="op">(</span><span class="va">final_poly_uncon</span>, n_important_coeffs <span class="op">=</span> <span class="fl">8</span><span class="op">)</span></span></code></pre></div>
<p><img src="includes/nn2poly-02-reg-n-important-1.png"></p>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_n_important_coeffs.html">plot_n_important_coeffs</a></span><span class="op">(</span><span class="va">final_poly_con</span>, n_important_coeffs <span class="op">=</span> <span class="fl">8</span><span class="op">)</span></span></code></pre></div>
<p><img src="includes/nn2poly-02-reg-n-important-2.png"></p>
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Pablo Morala, Iñaki Ucar.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>

<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="nn2poly">
<title>01 - Introduction to nn2poly • nn2poly</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="01 - Introduction to nn2poly">
<meta property="og:description" content="nn2poly">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">nn2poly</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.0.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/nn2poly-01-introduction.html">01 - Introduction to nn2poly</a>
    <a class="dropdown-item" href="../articles/nn2poly-02-tensorflow-regression.html">02 - Regression example using tensorflow</a>
    <a class="dropdown-item" href="../articles/nn2poly-03-tensorflow-classification.html">03 - Classification example using tensorflow</a>
  </div>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav"></ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>01 - Introduction to nn2poly</h1>
                        <h4 data-toc-skip class="author">Pablo
Morala</h4>
            
      
      
      <div class="d-none name"><code>nn2poly-01-introduction.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="overall-package-goal">Overall package goal<a class="anchor" aria-label="anchor" href="#overall-package-goal"></a>
</h2>
<p>The main objective of <code>nn2poly</code> is to obtain a
representation of a feed forward artificial neural network (like a
multilayered perceptron) in terms of a polynomial representation. The
coefficients of such polynomials are obtained by applying first a Taylor
expansion at each activation function in the neural network. Then this
expansions and the given neural network weights are joint using
combinatorial properties, obtaining a final value for the polynomial
coefficients.</p>
<p>More information with the theoretical insights about the underlying
mathematical process used to build this relationship can be found in the
following references: * Initial development of the idea for a single
hidden layer neural network in this <a href="https://doi.org/10.1016/j.neunet.2021.04.036" class="external-link">article</a> or its
free access <a href="https://doi.org/10.48550/arXiv.2102.03865" class="external-link">arXiv
preprint version</a>. * Extension to deeper layers and proper
formulation of the <em>NN2Poly</em> method in this <a href="https://doi.org/10.48550/arXiv.2112.11397" class="external-link">arXiv preprint</a>.</p>
<p><em>Important remark 1</em>: The approximations made by the NN2poly
method rely on Taylor expansions and therefore require some constraints
to be imposed when training the original neural network. The
implementation of these constraints depend on the deep learning
framework used to train the neural networks. Currently, this package
supports constraints implementation for <em>keras/tensorflow</em>,
covered in <code><a href="../articles/nn2poly-02-tensorflow-regression.html">vignette("nn2poly-02-tensorflow-regression")</a></code> and
<code><a href="../articles/nn2poly-03-tensorflow-classification.html">vignette("nn2poly-03-tensorflow-classification")</a></code>.
Implementation for <em>pytorch</em> networks is in development. However,
the <code>nn2poly</code> can work by default with any kind of neural
network by manually feeding the neural network weights and activation
functions to the algorithm. Therefore, <code>nn2poly</code> is not
limited to a special deep learning framework.</p>
</div>
<div class="section level2">
<h2 id="this-vignettes-goal">This vignette’s goal<a class="anchor" aria-label="anchor" href="#this-vignettes-goal"></a>
</h2>
<p>Here we present the basic behavior of <code>nn2poly</code> when used
in its default version, without specifying any deep learning framework
as explained in the previous remark. For that matter, we will showcase
an example where we will get the weights from a trained neural network
and manually create the object with the needed information to use
<code>nn2poly</code>.</p>
<p>The result will be a polynomial that tries to approximate the neural
network behavior. In this case the neural network training will not have
any constraint imposed. Then, as explained previously, the final
approximation by the polynomial may not be accurate enough.</p>
<p>This example is focused in the default version, but we need to build
a NN under some framework, we will use <code>keras</code> and
<code>tensorflow</code> for that matter. In any case, the needed
parameters will be extracted and used under the default version of
<code>nn2poly</code>, so this can be extrapolated to any other
framework.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://ibidat.github.io/nn2poly/">nn2poly</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://tensorflow.rstudio.com/" class="external-link">keras</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># This sets all needed seeds</span></span>
<span><span class="fu">tensorflow</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/set_random_seed.html" class="external-link">set_random_seed</a></span><span class="op">(</span><span class="fl">42</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="simple-regression-example">Simple regression example<a class="anchor" aria-label="anchor" href="#simple-regression-example"></a>
</h2>
<p>This example will solve a regression problem using simulated data
from a polynomial, which allows to control if the final polynomial
coefficients obtained with <code>nn2poly</code> are similar to those
from the polynomial that originates the data.</p>
<div class="section level3">
<h3 id="simulated-data-generation">Simulated data generation<a class="anchor" aria-label="anchor" href="#simulated-data-generation"></a>
</h3>
<p>We will simulate polynomial data as follows. First we define a
polynomial using the format needed in <code>nn2poly</code>, specifically
to use the function <code>eval_poly</code>, which consists of a list
containing: * Labels: A list of integer vectors denoting the
combinations of variables that appear on each term of the polynomial.
Variables are numbered from <code>1</code> to <code>p</code> where
<code>p</code> is the dimension of the problem. As an example,
<code>c(1,1,3)</code> would represent the term <span class="math inline">\(x_1^2x_3\)</span> * Values: Vector containing the
numerical values of the coefficients denoted by labels. If multiple
polynomials with the same terms but different coefficients want to be
represented, a matrix can be employed, where each row is a
polynomial.</p>
<p>Here we create the polynomial <span class="math inline">\(4x_1 - 3
x_2x_3\)</span>:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">polynomial</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">polynomial</span><span class="op">$</span><span class="va">labels</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">3</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">polynomial</span><span class="op">$</span><span class="va">values</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">4</span>,<span class="op">-</span><span class="fl">3</span><span class="op">)</span></span></code></pre></div>
<p>With said polynomial, we can now generate the desired data that will
train the NN for our example. We will employ a normal distribution to
generate variables <span class="math inline">\(x_1, x_2, x_3\)</span>
and also an error term <span class="math inline">\(\epsilon\)</span>.
Therefore, the response variable <span class="math inline">\(y\)</span>
will be generated as: <span class="math inline">\(y = 4x_1 - 3 x_2x_3 +
\epsilon\)</span></p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Define number of variables p and sample n</span></span>
<span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fl">3</span></span>
<span><span class="va">n_sample</span> <span class="op">&lt;-</span> <span class="fl">500</span></span>
<span></span>
<span><span class="co"># Predictor variables</span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fl">0</span>,<span class="va">n_sample</span>,<span class="va">p</span><span class="op">)</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">p</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="va">X</span><span class="op">[</span>,<span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n_sample</span>,<span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Response variable + small error term</span></span>
<span><span class="va">Y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/vector.html" class="external-link">as.vector</a></span><span class="op">(</span><span class="fu"><a href="../reference/eval_poly.html">eval_poly</a></span><span class="op">(</span><span class="va">X</span>,<span class="va">polynomial</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="fu">stats</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n_sample</span>, <span class="fl">0</span>, <span class="fl">0.1</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Store all as a data frame</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html" class="external-link">as.data.frame</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">Y</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span>
<span><span class="co">#&gt;           V1           V2         V3          Y</span></span>
<span><span class="co">#&gt; 1  1.3709584  1.029140719  2.3250585 -1.7547416</span></span>
<span><span class="co">#&gt; 2 -0.5646982  0.914774868  0.5241222 -3.7107357</span></span>
<span><span class="co">#&gt; 3  0.3631284 -0.002456267  0.9707334  1.3609395</span></span>
<span><span class="co">#&gt; 4  0.6328626  0.136009552  0.3769734  2.4608270</span></span>
<span><span class="co">#&gt; 5  0.4042683 -0.720153545 -0.9959334 -0.6141076</span></span>
<span><span class="co">#&gt; 6 -0.1061245 -0.198124330 -0.5974829 -0.7455793</span></span></code></pre></div>
<p>Then we will scale the data to have everything in the <span class="math inline">\([-1,1]\)</span> interval and divide it in train
and test datasets.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Data scaling</span></span>
<span><span class="va">maxs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">data</span>, <span class="fl">2</span>, <span class="va">max</span><span class="op">)</span></span>
<span><span class="va">mins</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">data</span>, <span class="fl">2</span>, <span class="va">min</span><span class="op">)</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html" class="external-link">as.data.frame</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/scale.html" class="external-link">scale</a></span><span class="op">(</span><span class="va">data</span>, center <span class="op">=</span> <span class="va">mins</span> <span class="op">+</span> <span class="op">(</span><span class="va">maxs</span> <span class="op">-</span> <span class="va">mins</span><span class="op">)</span> <span class="op">/</span> <span class="fl">2</span>, scale <span class="op">=</span> <span class="op">(</span><span class="va">maxs</span> <span class="op">-</span> <span class="va">mins</span><span class="op">)</span> <span class="op">/</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Divide in train (0.75) and test (0.25)</span></span>
<span><span class="va">index</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fl">0.75</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">train</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">[</span><span class="va">index</span>, <span class="op">]</span></span>
<span><span class="va">test</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">[</span><span class="op">-</span><span class="va">index</span>, <span class="op">]</span></span>
<span></span>
<span><span class="va">train_x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">train</span><span class="op">[</span>,<span class="op">-</span><span class="op">(</span><span class="va">p</span><span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="va">train_y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">train</span><span class="op">[</span>,<span class="op">(</span><span class="va">p</span><span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span>
<span></span>
<span><span class="va">test_x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">test</span><span class="op">[</span>,<span class="op">-</span><span class="op">(</span><span class="va">p</span><span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="va">test_y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">test</span><span class="op">[</span>,<span class="op">(</span><span class="va">p</span><span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="original-neural-network">Original neural network<a class="anchor" aria-label="anchor" href="#original-neural-network"></a>
</h3>
<p>With our simulated data ready, we can train our neural network. The
method is expected to be applied to a given trained densely connected
feed forward neural network (NN from now on), also referred as
multilayer perceptron (MLP). Therefore, as explained before, the method
used to train the NN can be used. Here we will use <code>keras</code>to
train it, but we will manually build the needed object with the weights
that has to be fed to the <code>nn2poly</code> algorithm <strong>as if
it was trained with any other framework</strong>. For more information
on the specific <code>keras</code> methods implemented in the package,
please refer to
<code><a href="../articles/nn2poly-02-tensorflow-regression.html">vignette("nn2poly-02-tensorflow-regression")</a></code> and
<code>vignette("nn2poly-02-tensorflow-classification")</code>.</p>
<p><em>Note</em>: Once again, note that, in order to avoid asymptotic
behavior of the method, it is important to impose some kind of
constraints when training the neural network weights. Details on how to
do this depend on the chosen deep learning framework and are covered in
the next vignettes.</p>
<p>First, we build the model.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">nn</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model_sequential.html" class="external-link">keras_model_sequential</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="va">nn</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html" class="external-link">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">10</span>,</span>
<span>                  activation <span class="op">=</span> <span class="st">"tanh"</span>,</span>
<span>                  input_shape <span class="op">=</span> <span class="va">p</span><span class="op">)</span></span>
<span></span>
<span><span class="va">nn</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html" class="external-link">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">10</span>,</span>
<span>                  activation <span class="op">=</span> <span class="st">"tanh"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">nn</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html" class="external-link">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">1</span>,</span>
<span>                  activation <span class="op">=</span> <span class="st">"linear"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">nn</span></span>
<span><span class="co">#&gt; Model: "sequential_15"</span></span>
<span><span class="co">#&gt; ________________________________________________________________________________</span></span>
<span><span class="co">#&gt;  Layer (type)                       Output Shape                    Param #     </span></span>
<span><span class="co">#&gt; ================================================================================</span></span>
<span><span class="co">#&gt;  dense_18 (Dense)                   (None, 10)                      40          </span></span>
<span><span class="co">#&gt;  dense_19 (Dense)                   (None, 10)                      110         </span></span>
<span><span class="co">#&gt;  dense_20 (Dense)                   (None, 1)                       11          </span></span>
<span><span class="co">#&gt; ================================================================================</span></span>
<span><span class="co">#&gt; Total params: 161</span></span>
<span><span class="co">#&gt; Trainable params: 161</span></span>
<span><span class="co">#&gt; Non-trainable params: 0</span></span>
<span><span class="co">#&gt; ________________________________________________________________________________</span></span></code></pre></div>
<p>Compile the model:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://generics.r-lib.org/reference/compile.html" class="external-link">compile</a></span><span class="op">(</span><span class="va">nn</span>,</span>
<span>        loss <span class="op">=</span> <span class="st">"mse"</span>,</span>
<span>        optimizer <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/optimizer_adam.html" class="external-link">optimizer_adam</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>        metrics <span class="op">=</span> <span class="st">"mse"</span><span class="op">)</span></span></code></pre></div>
<p>And train it:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">history</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span><span class="va">nn</span>,</span>
<span>               <span class="va">train_x</span>,</span>
<span>               <span class="va">train_y</span>,</span>
<span>               verbose <span class="op">=</span> <span class="fl">0</span>,</span>
<span>               epochs <span class="op">=</span> <span class="fl">300</span>,</span>
<span>               validation_split <span class="op">=</span> <span class="fl">0.3</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>We can visualize the training process:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">history</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure/nn2poly-01-reg-history-1.png"></p>
<p>And we can also visualize the NN predictions vs the original Y
values.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Obtain the predicted values with the NN to compare them</span></span>
<span><span class="va">prediction_NN</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">nn</span>, <span class="va">test_x</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Diagonal plot implemented in the package to quickly visualize and compare predictions</span></span>
<span><span class="fu"><a href="../reference/plot_diagonal.html">plot_diagonal</a></span><span class="op">(</span>x_axis <span class="op">=</span>  <span class="va">prediction_NN</span>, y_axis <span class="op">=</span>  <span class="va">test_y</span>, xlab <span class="op">=</span> <span class="st">"NN prediction"</span>, ylab <span class="op">=</span> <span class="st">"Original Y"</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure/nn2poly-01-reg-comparison-y-nn-1.png"></p>
<p><em>Note</em>: Recall that the NN performance is not addressed by
<code>nn2poly</code>, meaning that this performance could be either good
or bad and <code>nn2poly</code> still represent the NN behavior.</p>
</div>
<div class="section level3">
<h3 id="using-nn2poly-to-obtain-the-polynomial">Using nn2poly to obtain the polynomial<a class="anchor" aria-label="anchor" href="#using-nn2poly-to-obtain-the-polynomial"></a>
</h3>
<p>After the NN has been trained, using any chosen method by the user,
the parameters have to be extracted and reshaped, if needed, to match
the expected input of the function <code><a href="../reference/nn2poly_algorithm.html">nn2poly_algorithm()</a></code>.</p>
<p>This input should be an <code>object</code> formed by a list of
matrices with a weight matrix at each layer. The weights matrices should
be of dimension ((1+input) * output) where the first row corresponds to
the bias vector, and the rest of the rows correspond to each of the
ordered vector weights associated to each input.</p>
<p>In that list, the name of each element has to be the activation
function names of each layer. Currently supported activation functions
are <code>"tanh", "sigmoid", "softplus", "linear"</code>.</p>
<p>Particularly, the <code>keras</code> framework by default separates
kernel weights matrices of dimension (input * output) and bias vectors
(1 * output), so we need to add the bias as the first row of a matrix
((1+input) * output).</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">keras_weights</span> <span class="op">&lt;-</span> <span class="fu">keras</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/keras/man/get_weights.html" class="external-link">get_weights</a></span><span class="op">(</span><span class="va">nn</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Due to keras giving weights separated from the bias, we have twice the</span></span>
<span><span class="co"># elements that we want:</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">keras_weights</span><span class="op">)</span><span class="op">/</span><span class="fl">2</span></span>
<span><span class="va">nn_weights</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/vector.html" class="external-link">vector</a></span><span class="op">(</span>mode <span class="op">=</span> <span class="st">"list"</span>, length <span class="op">=</span> <span class="va">n</span><span class="op">)</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">n</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="va">nn_weights</span><span class="op">[[</span><span class="va">i</span><span class="op">]</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span><span class="va">keras_weights</span><span class="op">[[</span><span class="fl">2</span><span class="op">*</span><span class="va">i</span><span class="op">]</span><span class="op">]</span>, <span class="va">keras_weights</span><span class="op">[[</span><span class="fl">2</span><span class="op">*</span><span class="va">i</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># The activation functions stored as strings:</span></span>
<span><span class="va">af_string_names</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"tanh"</span>,<span class="st">"tanh"</span>, <span class="st">"linear"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">weights_object</span> <span class="op">&lt;-</span> <span class="va">nn_weights</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">weights_object</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="va">af_string_names</span></span>
<span></span>
<span><span class="va">weights_object</span></span>
<span><span class="co">#&gt; $tanh</span></span>
<span><span class="co">#&gt;            [,1]       [,2]      [,3]        [,4]        [,5]       [,6]</span></span>
<span><span class="co">#&gt; [1,]  0.2637966 -0.1632335 0.4649245 -0.20589803  0.04730094 -0.3763387</span></span>
<span><span class="co">#&gt; [2,]  0.2385524  0.1342811 0.2513933  0.48018309 -0.47788176  0.1631715</span></span>
<span><span class="co">#&gt; [3,] -0.7742428 -0.1097567 0.8174284  0.08418242  0.06163564  0.7477616</span></span>
<span><span class="co">#&gt; [4,] -0.6955228  0.5266028 0.5572206 -0.46307948  0.48515409 -0.7743985</span></span>
<span><span class="co">#&gt;            [,7]        [,8]        [,9]       [,10]</span></span>
<span><span class="co">#&gt; [1,] -0.2124885 -0.08747434 -0.07051360 -0.37202930</span></span>
<span><span class="co">#&gt; [2,]  0.6607828 -0.31218216 -0.01426336 -0.01626668</span></span>
<span><span class="co">#&gt; [3,] -0.8533844 -0.48116657  0.04514860 -0.70131820</span></span>
<span><span class="co">#&gt; [4,]  0.1162070  0.35274017  0.04112899 -0.56946415</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $tanh</span></span>
<span><span class="co">#&gt;              [,1]        [,2]        [,3]        [,4]        [,5]       [,6]</span></span>
<span><span class="co">#&gt;  [1,] -0.06261473  0.01255261  0.42954829  0.06141516  0.08550595  0.2265693</span></span>
<span><span class="co">#&gt;  [2,]  0.61023968 -0.15460493  0.32420215  0.16633785  0.25600886 -0.2739864</span></span>
<span><span class="co">#&gt;  [3,] -0.25070983 -0.05766810 -0.50344008  0.13009298 -0.03173310 -0.4047118</span></span>
<span><span class="co">#&gt;  [4,]  0.40872586  0.46675542  0.11527456  0.43078154  0.15864335  0.6346628</span></span>
<span><span class="co">#&gt;  [5,] -0.24814591  0.01059229  0.40011716  0.27607894 -0.46360433 -0.3692199</span></span>
<span><span class="co">#&gt;  [6,] -0.26658243  0.51526904 -0.09131107  0.37373766  0.26082405  0.4299564</span></span>
<span><span class="co">#&gt;  [7,]  0.51186675  0.12881947  0.67951459 -0.17605777  0.15393135  0.4613117</span></span>
<span><span class="co">#&gt;  [8,]  0.40394908 -0.42659599 -0.98550946 -0.15839998  0.02221864  0.3011585</span></span>
<span><span class="co">#&gt;  [9,]  0.50324774  0.11122702 -0.84318024 -0.02784178  0.31848624  0.2643846</span></span>
<span><span class="co">#&gt; [10,]  0.27406499 -0.11159007  0.02285146  0.35646623  0.25075704 -0.1359648</span></span>
<span><span class="co">#&gt; [11,] -0.52268207  0.45537508 -0.56030786  0.49129054 -0.03669148 -0.7891714</span></span>
<span><span class="co">#&gt;              [,7]        [,8]        [,9]         [,10]</span></span>
<span><span class="co">#&gt;  [1,]  0.08071607  0.16983804  0.08445328  0.0732324421</span></span>
<span><span class="co">#&gt;  [2,]  0.06122208 -0.04379337 -0.57018125 -0.3144004941</span></span>
<span><span class="co">#&gt;  [3,]  0.28472036  0.23372132 -0.47447795  0.0003889628</span></span>
<span><span class="co">#&gt;  [4,]  0.01778316 -0.29318872  0.07777876 -0.0302867368</span></span>
<span><span class="co">#&gt;  [5,] -0.53746992 -0.42425549 -0.48620722 -0.1922566146</span></span>
<span><span class="co">#&gt;  [6,] -0.41601449 -0.25669649 -0.28299403 -0.2540818155</span></span>
<span><span class="co">#&gt;  [7,] -0.22281407  0.40243641 -0.12623918 -0.4014825821</span></span>
<span><span class="co">#&gt;  [8,] -0.04859665 -0.38288346  0.25072047 -0.3935797811</span></span>
<span><span class="co">#&gt;  [9,]  0.48137835 -0.40863025  0.01616014 -0.5411312580</span></span>
<span><span class="co">#&gt; [10,] -0.32286894  0.09449039 -0.06011314 -0.4011713266</span></span>
<span><span class="co">#&gt; [11,]  0.14410253 -0.21469988  0.24569559  0.3822859824</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $linear</span></span>
<span><span class="co">#&gt;              [,1]</span></span>
<span><span class="co">#&gt;  [1,] -0.07251097</span></span>
<span><span class="co">#&gt;  [2,]  0.95829737</span></span>
<span><span class="co">#&gt;  [3,] -0.07316440</span></span>
<span><span class="co">#&gt;  [4,] -0.35980642</span></span>
<span><span class="co">#&gt;  [5,] -0.43944517</span></span>
<span><span class="co">#&gt;  [6,] -0.07012334</span></span>
<span><span class="co">#&gt;  [7,]  0.60509491</span></span>
<span><span class="co">#&gt;  [8,] -0.66404337</span></span>
<span><span class="co">#&gt;  [9,] -0.04713812</span></span>
<span><span class="co">#&gt; [10,] -0.79189116</span></span>
<span><span class="co">#&gt; [11,] -0.91330308</span></span></code></pre></div>
<p>Additionally, there are other parameters affecting properties of the
algorithm:</p>
<ul>
<li>
<code>q_taylor_vector</code>: A vector of integers containing the
order of the Taylor expansion performed at each layer. If the output
layer has a linear activation function, then the last value should be
1.</li>
</ul>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">q_taylor_vector</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">8</span>, <span class="fl">8</span>,  <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<ul>
<li>
<code>forced_max_Q</code>: (optional value) An integer value
denoting the maximum order of the terms computed in the polynomial.
Usually 2 or 3 should be enough in practice. Note that higher orders
suppose an explosion in the possible combinations. If the user does not
provide a value, the polynomial order grows multiplicatively with the
Taylor order at each hidden layer, therefore its better to start with
low values.</li>
</ul>
<p>When the input is in the desired shape, the nn2poly method can be
applied:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">final_poly</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nn2poly.html">nn2poly</a></span><span class="op">(</span>object <span class="op">=</span> <span class="va">weights_object</span>,</span>
<span>                      q_taylor_vector <span class="op">=</span> <span class="va">q_taylor_vector</span>,</span>
<span>                      forced_max_Q <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span></code></pre></div>
<p>We can have a glimpse at how the coefficients of the polynomial are
stored. Note that the structure is the same as explained for the
polynomial that generated the data, as a list with labels and values. In
this case, the obtained polynomial is up to order 3.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">final_poly</span></span>
<span><span class="co">#&gt; $labels</span></span>
<span><span class="co">#&gt; $labels[[1]]</span></span>
<span><span class="co">#&gt; [1] 0</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $labels[[2]]</span></span>
<span><span class="co">#&gt; [1] 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $labels[[3]]</span></span>
<span><span class="co">#&gt; [1] 2</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $labels[[4]]</span></span>
<span><span class="co">#&gt; [1] 3</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $labels[[5]]</span></span>
<span><span class="co">#&gt; [1] 1 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $labels[[6]]</span></span>
<span><span class="co">#&gt; [1] 1 2</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $labels[[7]]</span></span>
<span><span class="co">#&gt; [1] 1 3</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $labels[[8]]</span></span>
<span><span class="co">#&gt; [1] 2 2</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $labels[[9]]</span></span>
<span><span class="co">#&gt; [1] 2 3</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $labels[[10]]</span></span>
<span><span class="co">#&gt; [1] 3 3</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $labels[[11]]</span></span>
<span><span class="co">#&gt; [1] 1 1 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $labels[[12]]</span></span>
<span><span class="co">#&gt; [1] 1 1 2</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $labels[[13]]</span></span>
<span><span class="co">#&gt; [1] 1 1 3</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $labels[[14]]</span></span>
<span><span class="co">#&gt; [1] 1 2 2</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $labels[[15]]</span></span>
<span><span class="co">#&gt; [1] 1 2 3</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $labels[[16]]</span></span>
<span><span class="co">#&gt; [1] 1 3 3</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $labels[[17]]</span></span>
<span><span class="co">#&gt; [1] 2 2 2</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $labels[[18]]</span></span>
<span><span class="co">#&gt; [1] 2 2 3</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $labels[[19]]</span></span>
<span><span class="co">#&gt; [1] 2 3 3</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $labels[[20]]</span></span>
<span><span class="co">#&gt; [1] 3 3 3</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $values</span></span>
<span><span class="co">#&gt;            [,1]      [,2]       [,3]        [,4]       [,5]       [,6]</span></span>
<span><span class="co">#&gt; [1,] -0.1617715 0.7475098 0.09908831 -0.08050417 0.07277049 0.03545956</span></span>
<span><span class="co">#&gt;             [,7]      [,8]      [,9]      [,10]       [,11]     [,12]</span></span>
<span><span class="co">#&gt; [1,] 0.009334022 0.3035036 -2.559723 0.02124509 -0.08924709 0.2939184</span></span>
<span><span class="co">#&gt;           [,13]     [,14]       [,15]      [,16]     [,17]     [,18]      [,19]</span></span>
<span><span class="co">#&gt; [1,] 0.01080101 0.6197476 -0.04956815 0.07802355 0.5294107 -1.012448 -0.7079898</span></span>
<span><span class="co">#&gt;            [,20]</span></span>
<span><span class="co">#&gt; [1,] -0.05140071</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; attr(,"class")</span></span>
<span><span class="co">#&gt; [1] "nn2poly"</span></span></code></pre></div>
<p>Note that the output has the <code>nn2poly</code> class.</p>
</div>
<div class="section level3">
<h3 id="obtaining-polynomial-predictions">Obtaining polynomial predictions<a class="anchor" aria-label="anchor" href="#obtaining-polynomial-predictions"></a>
</h3>
<p>After obtaining the polynomial coefficients, we can use them to
predict the response variable <span class="math inline">\(Y\)</span>.
This is done by employing function <code>predcit</code>on an
<code>nn2poly</code> object and providing the new data to predict.</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># Obtain the predicted values for the test data with our polynomial</span></span>
<span><span class="va">prediction_poly</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span>object <span class="op">=</span> <span class="va">final_poly</span>,</span>
<span>                           newdata <span class="op">=</span> <span class="va">test_x</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="visualizing-the-results">Visualizing the results<a class="anchor" aria-label="anchor" href="#visualizing-the-results"></a>
</h3>
<p>It is advisable to always check that the predictions obtained with
the new polynomial do not differ too much from the original neural
network predictions (and in case they differ, we can also try to find
why by checking the Taylor expansions). To help with that, a couple of
functions are included that allow us to plot the results.</p>
<p>A simple plot comparing the polynomial and NN predictions can be
obtained with <code><a href="../reference/plot_diagonal.html">plot_diagonal()</a></code>, where the red diagonal line
represents where a perfect relationship between the NN and the
polynomial predictions would be obtained. In this example, as the
theoretical weights constraints have not been imposed, we can observe
how the approximation is not perfect.</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="fu"><a href="../reference/plot_diagonal.html">plot_diagonal</a></span><span class="op">(</span>x_axis <span class="op">=</span>  <span class="va">prediction_NN</span>, y_axis <span class="op">=</span>  <span class="va">prediction_poly</span>, xlab <span class="op">=</span> <span class="st">"NN prediction"</span>, ylab <span class="op">=</span> <span class="st">"Polynomial prediction"</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure/nn2poly-01-reg-comparison-polynomial-nn-1.png"></p>
<p>We can also plot the <span class="math inline">\(n\)</span> most
important coefficients in absolute value to compare which variables or
interactions are more relevant in the polynomial. Note that, as data
should be scaled to the <span class="math inline">\([-1,1]\)</span>
interval, interactions of order 2 or higher would usually need a higher
absolute value than the lower order coefficients to be more
relevant.</p>
<p>In this case we can see how the coefficients differ from the original
polynomial <span class="math inline">\(4x_1 - 3 x_2x_3\)</span>, as
there were no constraints on the neural network weights training.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_n_important_coeffs.html">plot_n_important_coeffs</a></span><span class="op">(</span><span class="va">final_poly</span>, <span class="fl">8</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure/nn2poly-01-reg-n-important-1.png"></p>
<p>Another convenient plot to show how the algorithm is affected by each
layer can be obtained with
<code><a href="../reference/plot_taylor_and_activation_potentials.html">plot_taylor_and_activation_potentials()</a></code>, where the
activation potentials at each neuron are computed and presented over the
Taylor expansion approximation of the activation function at each
layer.</p>
<p>In this case, as we have not used constraints in the NN training, the
activation potentials are not strictly centered around zero.</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_taylor_and_activation_potentials.html">plot_taylor_and_activation_potentials</a></span><span class="op">(</span>object <span class="op">=</span> <span class="va">nn</span>,</span>
<span>                                      data <span class="op">=</span> <span class="va">train</span>,</span>
<span>                                    q_taylor_vector <span class="op">=</span> <span class="va">q_taylor_vector</span>,</span>
<span>                                    forced_max_Q <span class="op">=</span> <span class="fl">3</span>,</span>
<span>                                    my_max_norm <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="st">"unconstrained"</span>,<span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [[1]]</span></span></code></pre></div>
<p><img src="figure/nn2poly-01-reg-potentials-1.png"></p>
<pre><code><span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[2]]</span></span></code></pre>
<p><img src="figure/nn2poly-01-reg-potentials-2.png"></p>
<pre><code><span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[3]]</span></span></code></pre>
<p><img src="figure/nn2poly-01-reg-potentials-3.png"></p>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Pablo Morala, Iñaki Ucar.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>

<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="nn2poly">
<title>02 - Regression example using tensorflow • nn2poly</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="02 - Regression example using tensorflow">
<meta property="og:description" content="nn2poly">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">nn2poly</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.0.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/nn2poly-01-introduction.html">01 - Introduction to nn2poly</a>
    <a class="dropdown-item" href="../articles/nn2poly-02-tensorflow-regression.html">02 - Regression example using tensorflow</a>
    <a class="dropdown-item" href="../articles/nn2poly-03-tensorflow-classification.html">03 - Classification example using tensorflow</a>
  </div>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav"></ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>02 - Regression example using tensorflow</h1>
                        <h4 data-toc-skip class="author">Pablo
Morala</h4>
            
            <h4 data-toc-skip class="date">2023-07-14</h4>
      
      
      <div class="d-none name"><code>nn2poly-02-tensorflow-regression.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="this-vignettes-goal">This vignette’s goal<a class="anchor" aria-label="anchor" href="#this-vignettes-goal"></a>
</h2>
<p>After showing how to use <code>nn2poly</code> in its default version
in <code><a href="../articles/nn2poly-01-introduction.html">vignette("nn2poly-01-introduction")</a></code>, here we will
present how to use specific methods related to <code>keras</code> and
<code>tensorflow</code> that allow for an easier and smoother use of
<code>nn2poly</code> with that deep learning framework. Furthermore, we
will sow how to impose the needed weight constraints in
<code>tensorflow</code> during training to have accurate results and
compare those results with an unconstrained neural network.</p>
<p>In this vignette we will focus on a simple regression example and a
classification one is covered in
<code><a href="../articles/nn2poly-03-tensorflow-classification.html">vignette("nn2poly-03-tensorflow-classification")</a></code>.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://ibidat.github.io/nn2poly/">nn2poly</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://tensorflow.rstudio.com/" class="external-link">keras</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># This sets all needed seeds</span></span>
<span><span class="fu">tensorflow</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/set_random_seed.html" class="external-link">set_random_seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="simple-regression-example">Simple regression example<a class="anchor" aria-label="anchor" href="#simple-regression-example"></a>
</h2>
<div class="section level3">
<h3 id="simulated-data-generation">Simulated data generation<a class="anchor" aria-label="anchor" href="#simulated-data-generation"></a>
</h3>
<p>We will simulate polynomial data from the following polynomial: <span class="math inline">\(4x_1 - 3 x_2x_3\)</span>. Data needs to be scaled
to the <span class="math inline">\([-1,1]\)</span> interval.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Define the desired polynomial for the simulated data</span></span>
<span><span class="va">polynomial</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">polynomial</span><span class="op">$</span><span class="va">labels</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">3</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">polynomial</span><span class="op">$</span><span class="va">values</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">4</span>,<span class="op">-</span><span class="fl">3</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Define number of variables p and sample n</span></span>
<span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fl">3</span></span>
<span><span class="va">n_sample</span> <span class="op">&lt;-</span> <span class="fl">500</span></span>
<span></span>
<span><span class="co"># Predictor variables</span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fl">0</span>,<span class="va">n_sample</span>,<span class="va">p</span><span class="op">)</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">p</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="va">X</span><span class="op">[</span>,<span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n_sample</span>,<span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Response variable + small error term</span></span>
<span><span class="va">Y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/vector.html" class="external-link">as.vector</a></span><span class="op">(</span><span class="fu"><a href="../reference/eval_poly.html">eval_poly</a></span><span class="op">(</span><span class="va">X</span>,<span class="va">polynomial</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="fu">stats</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n_sample</span>, <span class="fl">0</span>, <span class="fl">0.1</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Store all as a data frame</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html" class="external-link">as.data.frame</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">Y</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span>
<span><span class="co">#&gt;           V1          V2          V3         Y</span></span>
<span><span class="co">#&gt; 1 -0.6264538  0.07730312  1.13496509 -2.684020</span></span>
<span><span class="co">#&gt; 2  0.1836433 -0.29686864  1.11193185  1.632335</span></span>
<span><span class="co">#&gt; 3 -0.8356286 -1.18324224 -0.87077763 -6.344179</span></span>
<span><span class="co">#&gt; 4  1.5952808  0.01129269  0.21073159  6.279883</span></span>
<span><span class="co">#&gt; 5  0.3295078  0.99160104  0.06939565  1.165488</span></span>
<span><span class="co">#&gt; 6 -0.8204684  1.59396745 -1.66264885  4.650553</span></span></code></pre></div>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Data scaling</span></span>
<span><span class="va">maxs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">data</span>, <span class="fl">2</span>, <span class="va">max</span><span class="op">)</span></span>
<span><span class="va">mins</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">data</span>, <span class="fl">2</span>, <span class="va">min</span><span class="op">)</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html" class="external-link">as.data.frame</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/scale.html" class="external-link">scale</a></span><span class="op">(</span><span class="va">data</span>, center <span class="op">=</span> <span class="va">mins</span> <span class="op">+</span> <span class="op">(</span><span class="va">maxs</span> <span class="op">-</span> <span class="va">mins</span><span class="op">)</span> <span class="op">/</span> <span class="fl">2</span>, scale <span class="op">=</span> <span class="op">(</span><span class="va">maxs</span> <span class="op">-</span> <span class="va">mins</span><span class="op">)</span> <span class="op">/</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Divide in train (0.75) and test (0.25)</span></span>
<span><span class="va">index</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fl">0.75</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">train</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">[</span><span class="va">index</span>, <span class="op">]</span></span>
<span><span class="va">test</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">[</span><span class="op">-</span><span class="va">index</span>, <span class="op">]</span></span>
<span></span>
<span><span class="va">train_x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">train</span><span class="op">[</span>,<span class="op">-</span><span class="op">(</span><span class="va">p</span><span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="va">train_y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">train</span><span class="op">[</span>,<span class="op">(</span><span class="va">p</span><span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span>
<span></span>
<span><span class="va">test_x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">test</span><span class="op">[</span>,<span class="op">-</span><span class="op">(</span><span class="va">p</span><span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="va">test_y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">test</span><span class="op">[</span>,<span class="op">(</span><span class="va">p</span><span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure/nn2poly-02-reg-data-scaling-split-1.png"></p>
</div>
<div class="section level3">
<h3 id="original-neural-networks">Original neural networks<a class="anchor" aria-label="anchor" href="#original-neural-networks"></a>
</h3>
<p>We will build and train two different neural networks (NNs), one with
unconstrained weights (<code>nn1</code>) and another one imposing a
constraint on the weights (<code>nn2</code>).</p>
<p>Different constraints can be tested, but the suggested constraint
based on our theoretical and empirical evaluation is to use the L1 norm
equal to 1, constraining each vector of weights + bias arriving to a
neuron to satisfy that their L1 norm is equal or less than 1.</p>
<div class="section level4">
<h4 id="build-nn-1-unconstrained">Build NN 1, unconstrained<a class="anchor" aria-label="anchor" href="#build-nn-1-unconstrained"></a>
</h4>
<p>This NN will be built using standard tensorflow and keras practices,
in this case with a sequential keras model without any constraint on the
weights.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">nn1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model_sequential.html" class="external-link">keras_model_sequential</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="va">nn1</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html" class="external-link">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">100</span>,</span>
<span>                  activation <span class="op">=</span> <span class="st">"tanh"</span>,</span>
<span>                  input_shape <span class="op">=</span> <span class="va">p</span><span class="op">)</span></span>
<span></span>
<span><span class="va">nn1</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html" class="external-link">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">100</span>,</span>
<span>                  activation <span class="op">=</span> <span class="st">"tanh"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">nn1</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html" class="external-link">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">100</span>,</span>
<span>                  activation <span class="op">=</span> <span class="st">"tanh"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">nn1</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html" class="external-link">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">1</span>,</span>
<span>                  activation <span class="op">=</span> <span class="st">"linear"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">nn1</span></span>
<span><span class="co">#&gt; Model: "sequential_10"</span></span>
<span><span class="co">#&gt; ________________________________________________________________________________________________________________________</span></span>
<span><span class="co">#&gt;  Layer (type)                                         Output Shape                                    Param #           </span></span>
<span><span class="co">#&gt; ========================================================================================================================</span></span>
<span><span class="co">#&gt;  dense_15 (Dense)                                     (None, 100)                                     400               </span></span>
<span><span class="co">#&gt;  dense_16 (Dense)                                     (None, 100)                                     10100             </span></span>
<span><span class="co">#&gt;  dense_17 (Dense)                                     (None, 100)                                     10100             </span></span>
<span><span class="co">#&gt;  dense_18 (Dense)                                     (None, 1)                                       101               </span></span>
<span><span class="co">#&gt; ========================================================================================================================</span></span>
<span><span class="co">#&gt; Total params: 20,701</span></span>
<span><span class="co">#&gt; Trainable params: 20,701</span></span>
<span><span class="co">#&gt; Non-trainable params: 0</span></span>
<span><span class="co">#&gt; ________________________________________________________________________________________________________________________</span></span></code></pre></div>
</div>
<div class="section level4">
<h4 id="build-nn-2-constrained">Build NN 2, constrained<a class="anchor" aria-label="anchor" href="#build-nn-2-constrained"></a>
</h4>
<p>In order to implement the desired constraints, we provide the
<code><a href="../reference/add_constraints.html">add_constraints()</a></code> function, that takes the structure of a
given NN (has to be a feed forward dense NN) and modifies its layers to
include the constraints. This is needed because default constraints
implemented in <code>keras</code> do not support to impose a constraint
at the same time on the weights and the bias and have to be combined
with a custom layer.</p>
<p>Our implementation is such that the bias on each neuron is included
in the weights vector incident on that neuron, meaning that if the
previous layer had <span class="math inline">\(h\)</span> neurons, then
the considered weight vector including the bias at a given neuron would
have dimension <span class="math inline">\(h+1\)</span>, having the bias
as it first element. Currently, L1 norm and L2 norm equal to 1 are
implemented as options.</p>
<p>Note that L1 norm equal to 1 when scaling the input data to the <span class="math inline">\([-1,1]\)</span> interval is the recommended
option.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">nn2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/add_constraints.html">add_constraints</a></span><span class="op">(</span><span class="va">nn1</span>, constraint_type <span class="op">=</span> <span class="st">"l1_norm"</span><span class="op">)</span></span>
<span><span class="va">nn2</span></span>
<span><span class="co">#&gt; Model: "sequential_11"</span></span>
<span><span class="co">#&gt; ________________________________________________________________________________________________________________________</span></span>
<span><span class="co">#&gt;  Layer (type)                                         Output Shape                                    Param #           </span></span>
<span><span class="co">#&gt; ========================================================================================================================</span></span>
<span><span class="co">#&gt;  layer__combined_l1_5 (Layer_Combined_L1)             (None, 100)                                     400               </span></span>
<span><span class="co">#&gt;  layer__combined_l1_6 (Layer_Combined_L1)             (None, 100)                                     10100             </span></span>
<span><span class="co">#&gt;  layer__combined_l1_7 (Layer_Combined_L1)             (None, 100)                                     10100             </span></span>
<span><span class="co">#&gt;  dense_19 (Dense)                                     (None, 1)                                       101               </span></span>
<span><span class="co">#&gt; ========================================================================================================================</span></span>
<span><span class="co">#&gt; Total params: 20,701</span></span>
<span><span class="co">#&gt; Trainable params: 20,701</span></span>
<span><span class="co">#&gt; Non-trainable params: 0</span></span>
<span><span class="co">#&gt; ________________________________________________________________________________________________________________________</span></span></code></pre></div>
<p>Note how the parameters and structure are the same, but the layer
type has been modified.</p>
</div>
<div class="section level4">
<h4 id="compile-and-train-both-nns">Compile and train both NNs<a class="anchor" aria-label="anchor" href="#compile-and-train-both-nns"></a>
</h4>
<p>After building both NNs, we compile and train both of them. Note
that, as constraining the weights has trade-off in the learning speed of
the NN, the <code>nn2</code> needs a higher number of epochs to properly
learn from the data.</p>
<p>Compile and train <code>nn1</code> the model, and visualize its
training history:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://generics.r-lib.org/reference/compile.html" class="external-link">compile</a></span><span class="op">(</span><span class="va">nn1</span>,</span>
<span>        loss <span class="op">=</span> <span class="st">"mse"</span>,</span>
<span>        optimizer <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/optimizer_adam.html" class="external-link">optimizer_adam</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>        metrics <span class="op">=</span> <span class="st">"mse"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">history1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span><span class="va">nn1</span>,</span>
<span>               <span class="va">train_x</span>,</span>
<span>               <span class="va">train_y</span>,</span>
<span>               verbose <span class="op">=</span> <span class="fl">0</span>,</span>
<span>               epochs <span class="op">=</span> <span class="fl">300</span>,</span>
<span>               batch_size <span class="op">=</span> <span class="fl">50</span>,</span>
<span>               validation_split <span class="op">=</span> <span class="fl">0.2</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">history1</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure/nn2poly-02-reg-nn1-train-1.png"></p>
<p>Compile and train <code>nn2</code> the model, and visualize its
training history:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://generics.r-lib.org/reference/compile.html" class="external-link">compile</a></span><span class="op">(</span><span class="va">nn2</span>,</span>
<span>        loss <span class="op">=</span> <span class="st">"mse"</span>,</span>
<span>        optimizer <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/optimizer_adam.html" class="external-link">optimizer_adam</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>        metrics <span class="op">=</span> <span class="st">"mse"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">history2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span><span class="va">nn2</span>,</span>
<span>               <span class="va">train_x</span>,</span>
<span>               <span class="va">train_y</span>,</span>
<span>               verbose <span class="op">=</span> <span class="fl">0</span>,</span>
<span>               epochs <span class="op">=</span> <span class="fl">2000</span>,</span>
<span>               batch_size <span class="op">=</span> <span class="fl">50</span>,</span>
<span>               validation_split <span class="op">=</span> <span class="fl">0.2</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">history2</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure/nn2poly-02-reg-nn2-train-1.png"></p>
</div>
<div class="section level4">
<h4 id="visualize-both-nn-predictions">Visualize both NN predictions<a class="anchor" aria-label="anchor" href="#visualize-both-nn-predictions"></a>
</h4>
<p>We can visualize the NN predictions vs the original Y values for both
neural networks and observe how both of them provide accurate
predictions (the values fall near the “perfect” diagonal red line).</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Obtain the predicted values with the NN to compare them</span></span>
<span><span class="va">prediction_NN1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">nn1</span>, <span class="va">test_x</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Diagonal plot implemented in the package to quickly visualize and compare predictions</span></span>
<span><span class="fu"><a href="../reference/plot_diagonal.html">plot_diagonal</a></span><span class="op">(</span>x_axis <span class="op">=</span>  <span class="va">prediction_NN1</span>, y_axis <span class="op">=</span>  <span class="va">test_y</span>, xlab <span class="op">=</span> <span class="st">"NN 1 prediction"</span>, ylab <span class="op">=</span> <span class="st">"Original Y"</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure/nn2poly-02-reg-comparison-y-nn1-1.png"></p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Obtain the predicted values with the NN to compare them</span></span>
<span><span class="va">prediction_NN2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">nn2</span>, <span class="va">test_x</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Diagonal plot implemented in the package to quickly visualize and compare predictions</span></span>
<span><span class="fu"><a href="../reference/plot_diagonal.html">plot_diagonal</a></span><span class="op">(</span>x_axis <span class="op">=</span>  <span class="va">prediction_NN2</span>, y_axis <span class="op">=</span>  <span class="va">test_y</span>, xlab <span class="op">=</span> <span class="st">"NN 2 prediction"</span>, ylab <span class="op">=</span> <span class="st">"Original Y"</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure/nn2poly-02-reg-comparison-y-nn2-1.png"></p>
</div>
</div>
<div class="section level3">
<h3 id="using-nn2poly-to-obtain-the-polynomial">Using nn2poly to obtain the polynomial<a class="anchor" aria-label="anchor" href="#using-nn2poly-to-obtain-the-polynomial"></a>
</h3>
<p>After the NNs have been trained, we can directly call
<code>nn2poly</code> on the <code>keras</code> model. Therefore, we do
not need to build an object with weights and activation functions as in
the default case covered in
<code><a href="../articles/nn2poly-01-introduction.html">vignette("nn2poly-01-introduction")</a></code>, and can benefit from
the generic methods implemented for <code>keras</code> models.</p>
<p>The only parameters that have to be added for nn2poly to work is the
Taylor order expansion at each layer (<code>q_taylor_vector</code>),
where we will choose 8 by default on non linear layers and 1 in the last
linear layer as Taylor is not used there. (The final polynomial order
will be limited by <code>forced_max_Q=3</code>)</p>
<p>We will do this for both neural networks and compare the results:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">q_taylor_vector</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">8</span>, <span class="fl">8</span>, <span class="fl">8</span>, <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Polynomial for nn1</span></span>
<span><span class="va">final_poly1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nn2poly.html">nn2poly</a></span><span class="op">(</span>object <span class="op">=</span> <span class="va">nn1</span>,</span>
<span>                      q_taylor_vector <span class="op">=</span> <span class="va">q_taylor_vector</span>,</span>
<span>                      forced_max_Q <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Polynomial for nn2</span></span>
<span><span class="va">final_poly2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nn2poly.html">nn2poly</a></span><span class="op">(</span>object <span class="op">=</span> <span class="va">nn2</span>,</span>
<span>                      q_taylor_vector <span class="op">=</span> <span class="va">q_taylor_vector</span>,</span>
<span>                      forced_max_Q <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="obtaining-polynomial-predictions">Obtaining polynomial predictions<a class="anchor" aria-label="anchor" href="#obtaining-polynomial-predictions"></a>
</h3>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># Obtain the predicted values for the test data with our two polynomials</span></span>
<span></span>
<span><span class="va">prediction_poly1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/eval_poly.html">eval_poly</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">test_x</span>, poly <span class="op">=</span> <span class="va">final_poly1</span><span class="op">)</span></span>
<span></span>
<span><span class="va">prediction_poly2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/eval_poly.html">eval_poly</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">test_x</span>, poly <span class="op">=</span> <span class="va">final_poly2</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="visualizing-the-results">Visualizing the results<a class="anchor" aria-label="anchor" href="#visualizing-the-results"></a>
</h3>
<p>With the polynomial predictions, we can plot them using our diagonal
plot to compare them with their respective NN predictions. Please note
here that we compare the predictions of the polynomial with the NN
predictions and not the original data, as <code>nn2poly</code>’s goal is
to faithfully represent the NN behavior independently of how well the NN
predicts.</p>
<p>We can observe clearly how the polynomial obtained for the
constrained network (<code>nn2</code>) is predicting almost the same,
while the unconstrained network has significant errors.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_diagonal.html">plot_diagonal</a></span><span class="op">(</span>x_axis <span class="op">=</span>  <span class="va">prediction_NN1</span>, y_axis <span class="op">=</span>  <span class="va">prediction_poly1</span>, xlab <span class="op">=</span> <span class="st">"NN prediction"</span>, ylab <span class="op">=</span> <span class="st">"Polynomial prediction"</span><span class="op">)</span> <span class="op">+</span> <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">ggtitle</a></span><span class="op">(</span><span class="st">"Polynomial for NN1"</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure/nn2poly-02-reg-comparison-polynomial-nn-1.png"></p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="fu"><a href="../reference/plot_diagonal.html">plot_diagonal</a></span><span class="op">(</span>x_axis <span class="op">=</span>  <span class="va">prediction_NN2</span>, y_axis <span class="op">=</span>  <span class="va">prediction_poly2</span>, xlab <span class="op">=</span> <span class="st">"NN prediction"</span>, ylab <span class="op">=</span> <span class="st">"Polynomial prediction"</span><span class="op">)</span> <span class="op">+</span> <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">ggtitle</a></span><span class="op">(</span><span class="st">"Polynomial for NN2"</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure/nn2poly-02-reg-comparison-polynomial-nn-2.png"></p>
<p>We can also plot the <span class="math inline">\(n\)</span> most
important coefficients in absolute value to compare which variables or
interactions are more relevant in the polynomial. Note that, as data
should be scaled to the <span class="math inline">\([-1,1]\)</span>
interval, interactions of order 2 or higher would usually need a higher
absolute value than the lower order coefficients to be more
relevant.</p>
<p>Recall that the original polynomial was <span class="math inline">\(4x_1 - 3x_2x_3\)</span>. If we observe the
polynomial from <code>nn2</code>, precisely interaction <code>2,3</code>
has a high negative coefficient while variable <code>1</code> has a
positive one and the rest of variables and the intercept
(<code>0</code>) are quite close to zero. However, in the polynomial
from <code>nn1</code>, the obtained coefficients are not correct as
Taylor expansion is failing because of the high weights.</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_n_important_coeffs.html">plot_n_important_coeffs</a></span><span class="op">(</span><span class="va">final_poly1</span>, n_important_coeffs <span class="op">=</span> <span class="fl">8</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure/nn2poly-02-reg-n-important-1.png"></p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_n_important_coeffs.html">plot_n_important_coeffs</a></span><span class="op">(</span><span class="va">final_poly2</span>, n_important_coeffs <span class="op">=</span> <span class="fl">8</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure/nn2poly-02-reg-n-important-2.png"></p>
<p>Finally, the problem with Taylor expansion can be checked with the
following plot, where each layer is represented with their activation
function, its Taylor expansion, the error and also the density of the
activation potentials that the activation functions receives at that
layer.</p>
<p>It can be clearly seen with the activation potentials density, in
green, that it expands over a wide range in the unconstrained NN while
the it is kept closer to zero in the constrained one, thus having a more
accurate Taylor expansion around zero.</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_taylor_and_activation_potentials.html">plot_taylor_and_activation_potentials</a></span><span class="op">(</span>object <span class="op">=</span> <span class="va">nn1</span>,</span>
<span>                                      data <span class="op">=</span> <span class="va">train</span>,</span>
<span>                                      q_taylor_vector <span class="op">=</span> <span class="va">q_taylor_vector</span>,</span>
<span>                                      forced_max_Q <span class="op">=</span> <span class="fl">3</span>,</span>
<span>                                      constraints <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="co">#&gt; [[1]]</span></span></code></pre></div>
<p><img src="figure/nn2poly-02-reg-potentials-1.png"></p>
<pre><code><span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[2]]</span></span></code></pre>
<p><img src="figure/nn2poly-02-reg-potentials-2.png"></p>
<pre><code><span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[3]]</span></span></code></pre>
<p><img src="figure/nn2poly-02-reg-potentials-3.png"></p>
<pre><code><span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[4]]</span></span></code></pre>
<p><img src="figure/nn2poly-02-reg-potentials-4.png"></p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="fu"><a href="../reference/plot_taylor_and_activation_potentials.html">plot_taylor_and_activation_potentials</a></span><span class="op">(</span>object <span class="op">=</span> <span class="va">nn2</span>,</span>
<span>                                      data <span class="op">=</span> <span class="va">train</span>,</span>
<span>                                      q_taylor_vector <span class="op">=</span> <span class="va">q_taylor_vector</span>,</span>
<span>                                      forced_max_Q <span class="op">=</span> <span class="fl">3</span>,</span>
<span>                                      constraints <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; [[1]]</span></span></code></pre></div>
<p><img src="figure/nn2poly-02-reg-potentials-5.png"></p>
<pre><code><span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[2]]</span></span></code></pre>
<p><img src="figure/nn2poly-02-reg-potentials-6.png"></p>
<pre><code><span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[3]]</span></span></code></pre>
<p><img src="figure/nn2poly-02-reg-potentials-7.png"></p>
<pre><code><span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[4]]</span></span></code></pre>
<p><img src="figure/nn2poly-02-reg-potentials-8.png"></p>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Pablo Morala, Iñaki Ucar.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>

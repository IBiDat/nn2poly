<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Introduction to nn2pr â€¢ nn2pr</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Introduction to nn2pr">
<meta property="og:description" content="nn2pr">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">nn2pr</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.0.0.9000</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/nn2pr-01-introduction.html">Introduction to nn2pr</a>
    </li>
    <li>
      <a href="../articles/nn2pr-02-using-some-tools.html">nn2pr-02-using-some-tools</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="nn2pr-01-introduction_files/header-attrs-2.11/header-attrs.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Introduction to nn2pr</h1>
                        <h4 class="author">Pablo Morala</h4>
            
            <h4 class="date">2021-10-08</h4>
      
      
      <div class="hidden name"><code>nn2pr-01-introduction.Rmd</code></div>

    </div>

    
    
<p>Initial setup:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">nn2pr</span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://keras.rstudio.com">keras</a></span><span class="op">)</span>
<span class="co">#&gt; Warning: package 'keras' was built under R version 4.0.5</span>
<span class="fu">tensorflow</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/set_random_seed.html">set_random_seed</a></span><span class="op">(</span><span class="fl">42</span><span class="op">)</span></code></pre></div>
<div id="overall-goal" class="section level1">
<h1 class="hasAnchor">
<a href="#overall-goal" class="anchor"></a>Overall Goal</h1>
<p>The main objective of this package is obtaining a representation of a feed forward neural network in terms of a polynomial regression. This is achieved by applying a Taylor extension at each activation function in the neural network, and combining that with its trained weights, the coefficients of a polynomial regression are obtained.</p>
<p>The main insights about the mathematical process to build this relationship can be found in this <a href="https://doi.org/10.1016/j.neunet.2021.04.036">article</a> or its free access option through the orginal <a href="https://arxiv.org/abs/2102.03865.">arXiv version</a>.</p>
<p>This vignette presents the direct usage of the package with a simple case. For additional tools to build neural networks with the needed conditions that ensure the correct theoretical behavior (constraining the weights and biases), check the VIGNETTE 2 that also uses the extension package <code>nn2prtools</code>.</p>
</div>
<div id="data-preparation" class="section level1">
<h1 class="hasAnchor">
<a href="#data-preparation" class="anchor"></a>Data preparation</h1>
<p>In order to show the most common application of <code>nn2pr</code>, we will be solving a regression problem on the Boston dataset, included in the <code>keras</code>package.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">boston_housing</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://keras.rstudio.com/reference/dataset_boston_housing.html">dataset_boston_housing</a></span><span class="op">(</span><span class="op">)</span>

<span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">train_x</span>, <span class="va">train_y</span><span class="op">)</span> <span class="op">%&lt;-%</span> <span class="va">boston_housing</span><span class="op">$</span><span class="va">train</span>
<span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">test_x</span>, <span class="va">test_y</span><span class="op">)</span> <span class="op">%&lt;-%</span> <span class="va">boston_housing</span><span class="op">$</span><span class="va">test</span></code></pre></div>
<p>The data needs to be scaled, both for training the NN and for the <code>nn2pr</code> algorithm to work properly. In the theoretical foundation of this method, the scaling assumed is to the <span class="math inline">\([-1,1]\)</span> interval, so we will use it:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Join the predictor variables (x) and the response (y)</span>
<span class="va">train</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span><span class="op">(</span><span class="va">train_x</span><span class="op">)</span>
<span class="va">train</span><span class="op">$</span><span class="va">Y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="va">train_y</span>, ncol <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>

<span class="va">test</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span><span class="op">(</span><span class="va">test_x</span><span class="op">)</span>
<span class="va">test</span><span class="op">$</span><span class="va">Y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="va">test_y</span>, ncol <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>

<span class="co"># Use the train data to obtain the scaling parameters, then apply them both to </span>
<span class="co"># test and train</span>
<span class="va">maxs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">train</span>, <span class="fl">2</span>, <span class="va">max</span><span class="op">)</span>
<span class="va">mins</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">train</span>, <span class="fl">2</span>, <span class="va">min</span><span class="op">)</span> 

<span class="va">train</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/scale.html">scale</a></span><span class="op">(</span><span class="va">train</span>, 
                             center <span class="op">=</span> <span class="va">mins</span> <span class="op">+</span> <span class="op">(</span><span class="va">maxs</span> <span class="op">-</span> <span class="va">mins</span><span class="op">)</span> <span class="op">/</span> <span class="fl">2</span>, 
                             scale <span class="op">=</span> <span class="op">(</span><span class="va">maxs</span> <span class="op">-</span> <span class="va">mins</span><span class="op">)</span> <span class="op">/</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span>
<span class="va">test</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/scale.html">scale</a></span><span class="op">(</span><span class="va">test</span>, 
                             center <span class="op">=</span> <span class="va">mins</span> <span class="op">+</span> <span class="op">(</span><span class="va">maxs</span> <span class="op">-</span> <span class="va">mins</span><span class="op">)</span> <span class="op">/</span> <span class="fl">2</span>, 
                             scale <span class="op">=</span> <span class="op">(</span><span class="va">maxs</span> <span class="op">-</span> <span class="va">mins</span><span class="op">)</span> <span class="op">/</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span>

<span class="co"># Divide again in x and y</span>
<span class="va">train_x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/subset.html">subset</a></span><span class="op">(</span><span class="va">train</span>, select <span class="op">=</span> <span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">Y</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
<span class="va">train_y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">train</span><span class="op">$</span><span class="va">Y</span><span class="op">)</span>

<span class="va">test_x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/subset.html">subset</a></span><span class="op">(</span><span class="va">test</span>, select <span class="op">=</span> <span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">Y</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
<span class="va">test_y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">test</span><span class="op">$</span><span class="va">Y</span><span class="op">)</span>

<span class="co"># Define the dimension p of the problem:</span>
<span class="va">p</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">train_x</span><span class="op">)</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span></code></pre></div>
</div>
<div id="original-neural-network" class="section level1">
<h1 class="hasAnchor">
<a href="#original-neural-network" class="anchor"></a>Original neural network</h1>
<p>The method is expected to be applied to a given trained densely connected feed forward neural network (NN from now on), also referred as multilayer perceptron (MLP). Therefore, this step is completely <strong>optional</strong> and can be skipped if any preferred method has been used to train a NN and there is an already given NN and its weights.</p>
<p>In order to present an example, here we will create and train a NN. Our choice will be to use the <code>keras</code> framework to build and train it.</p>
<table class="table"><tbody><tr class="odd">
<td>
<em>Note</em>: It is important to note that in order to avoid asymptotic behavior of the method, it is useful to impose some kind of constraint when training the neural network weights. This is covered in VIGNETTE 2</td>
</tr></tbody></table>
<p>First, we build the model</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">nn</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://keras.rstudio.com/reference/keras_model_sequential.html">keras_model_sequential</a></span><span class="op">(</span><span class="op">)</span>

<span class="va">nn</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://keras.rstudio.com/reference/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">30</span>,
                  activation <span class="op">=</span> <span class="st">"softplus"</span>,
                  input_shape <span class="op">=</span> <span class="va">p</span><span class="op">)</span>
  
<span class="va">nn</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://keras.rstudio.com/reference/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">30</span>,
                  activation <span class="op">=</span> <span class="st">"softplus"</span><span class="op">)</span>

<span class="va">nn</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://keras.rstudio.com/reference/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">1</span>,
                  activation <span class="op">=</span> <span class="st">"linear"</span><span class="op">)</span>

<span class="va">nn</span>
<span class="co">#&gt; Model</span>
<span class="co">#&gt; Model: "sequential"</span>
<span class="co">#&gt; ________________________________________________________________________________</span>
<span class="co">#&gt; Layer (type)                        Output Shape                    Param #     </span>
<span class="co">#&gt; ================================================================================</span>
<span class="co">#&gt; dense (Dense)                       (None, 30)                      420         </span>
<span class="co">#&gt; ________________________________________________________________________________</span>
<span class="co">#&gt; dense_1 (Dense)                     (None, 30)                      930         </span>
<span class="co">#&gt; ________________________________________________________________________________</span>
<span class="co">#&gt; dense_2 (Dense)                     (None, 1)                       31          </span>
<span class="co">#&gt; ================================================================================</span>
<span class="co">#&gt; Total params: 1,381</span>
<span class="co">#&gt; Trainable params: 1,381</span>
<span class="co">#&gt; Non-trainable params: 0</span>
<span class="co">#&gt; ________________________________________________________________________________</span></code></pre></div>
<p>Compile the model:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://generics.r-lib.org/reference/compile.html">compile</a></span><span class="op">(</span><span class="va">nn</span>,
        loss <span class="op">=</span> <span class="st">"mse"</span>,
        optimizer <span class="op">=</span> <span class="fu"><a href="https://keras.rstudio.com/reference/optimizer_adam.html">optimizer_adam</a></span><span class="op">(</span><span class="op">)</span>,
        metrics <span class="op">=</span> <span class="st">"mse"</span><span class="op">)</span></code></pre></div>
<p>And train it:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">history</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html">fit</a></span><span class="op">(</span><span class="va">nn</span>,
               <span class="va">train_x</span>,
               <span class="va">train_y</span>,
               verbose <span class="op">=</span> <span class="fl">0</span>,
               epochs <span class="op">=</span> <span class="fl">50</span>,
               validation_split <span class="op">=</span> <span class="fl">0.3</span>
<span class="op">)</span></code></pre></div>
<p>We can visualize the training process:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">history</span><span class="op">)</span>
<span class="co">#&gt; `geom_smooth()` using formula 'y ~ x'</span></code></pre></div>
<p><img src="nn2pr-01-introduction_files/figure-html/unnamed-chunk-7-1.png" width="700"></p>
<table class="table"><tbody><tr class="odd">
<td>VisualizaciÃ³n de la NN, cambiar la funcion:</td>
</tr></tbody></table>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Obtain the predicted values with the NN to compare them</span>
<span class="va">prediction_NN</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">nn</span>, <span class="va">test_x</span><span class="op">)</span>

<span class="fu"><a href="../reference/plot_NN_PR_comparison.html">plot_NN_PR_comparison</a></span><span class="op">(</span><span class="va">test_y</span>, <span class="va">prediction_NN</span><span class="op">)</span></code></pre></div>
<p><img src="nn2pr-01-introduction_files/figure-html/unnamed-chunk-8-1.png" width="700"></p>
</div>
<div id="obtaining-the-polynomial-regression" class="section level1">
<h1 class="hasAnchor">
<a href="#obtaining-the-polynomial-regression" class="anchor"></a>Obtaining the polynomial regression</h1>
<p>After the NN has been trained, using any chosen method by the user, the parameters have to be extracted and reshaped, if needed, to match the expected input of the function <code><a href="../reference/nn2pr_algorithm.html">nn2pr_algorithm()</a></code>. This input consists in the following objects:</p>
<ul>
<li>
<code>weights_list</code> A list of matrices with a weight matrix at each layer. The weights matrices should be of dimension ((1+input) * output) where the first row corresponds to the bias vector, and the rest of the rows correspond to each of the ordered vector weights associated to each input.</li>
<li>
<code>af_string_list</code> A list of strings with the names of the activation functions at each layer.</li>
<li>
<code>q_taylor_vector</code> A vector of integers containing the order of the Taylor expansion performed at each layer. If the output layer has a linear activation function, then the last value should be 1.</li>
</ul>
<p>Following the example of the NN that we created previously, we need to extract its weights and biases and reshape them. Particularly, the <code>keras</code> framework by default separates kernel weights matrices of dimension (input * output) and bias vectors (1 * output), so we need to add the bias as the first row of a matrix ((1+input) * output).</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">keras_weights</span> <span class="op">&lt;-</span> <span class="fu">keras</span><span class="fu">::</span><span class="fu"><a href="https://keras.rstudio.com/reference/get_weights.html">get_weights</a></span><span class="op">(</span><span class="va">nn</span><span class="op">)</span>

<span class="co"># Due to keras giving weights separated from the bias, we have twice the </span>
<span class="co"># elements that we want:</span>
<span class="va">n</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">keras_weights</span><span class="op">)</span><span class="op">/</span><span class="fl">2</span>
<span class="va">nn_weights</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/vector.html">vector</a></span><span class="op">(</span>mode <span class="op">=</span> <span class="st">"list"</span>, length <span class="op">=</span> <span class="va">n</span><span class="op">)</span>
<span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">n</span><span class="op">)</span><span class="op">{</span>
  <span class="va">nn_weights</span><span class="op">[[</span><span class="va">i</span><span class="op">]</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="va">keras_weights</span><span class="op">[[</span><span class="fl">2</span><span class="op">*</span><span class="va">i</span><span class="op">]</span><span class="op">]</span>, <span class="va">keras_weights</span><span class="op">[[</span><span class="fl">2</span><span class="op">*</span><span class="va">i</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">)</span>
<span class="op">}</span></code></pre></div>
<p>The activation functions that we used can be stored as:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">af_string_list</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="st">"softplus"</span>,<span class="st">"softplus"</span>, <span class="st">"linear"</span><span class="op">)</span></code></pre></div>
<p>And finally the order of the Taylor approximation that we are going to choose is 3 at each hidden layer.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">q_taylor_vector</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">2</span>,  <span class="fl">1</span><span class="op">)</span> </code></pre></div>
<p>When the input is in the desired shape, the method can be applied finally:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">historical_coeffs</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nn2pr_algorithm.html">nn2pr_algorithm</a></span><span class="op">(</span>
  weights_list <span class="op">=</span> <span class="va">nn_weights</span>,
  af_string_list <span class="op">=</span> <span class="va">af_string_list</span>,
  q_taylor_vector <span class="op">=</span> <span class="va">q_taylor_vector</span>
<span class="op">)</span>
<span class="co">#&gt; [1] "partitions obtained"</span>

<span class="va">coeffs</span> <span class="op">&lt;-</span> <span class="va">historical_coeffs</span><span class="op">[[</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">historical_coeffs</span><span class="op">)</span><span class="op">]</span><span class="op">]</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span></code></pre></div>
<p>We can have a glimpse at how the coefficients of the pollynomial regression (PR) are stored.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">coeffs</span><span class="op">[</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">7</span><span class="op">]</span>
<span class="co">#&gt;           0           1           2           3           4           5 </span>
<span class="co">#&gt; -0.50570969 -0.02288363  0.06290509 -0.06092172  0.04301074 -0.07196644 </span>
<span class="co">#&gt;           6 </span>
<span class="co">#&gt;  0.38009198</span></code></pre></div>
</div>
<div id="visualising-the-results" class="section level1">
<h1 class="hasAnchor">
<a href="#visualising-the-results" class="anchor"></a>Visualising the results</h1>
<p>After using the algorithm, it is advisable to always check that the predictions obtained with the new polynomial regression do not differ too much from the original neural network predictions (and in case they differ, we can also try to find why by checking the Taylor expansions).To help with that, a couple of functions are included that allow us to plot the results.</p>
<p>First of all, after obtaining the PR coefficients, we want to use them to predict the response variable <span class="math inline">\(Y\)</span>, which can be done with the function <code><a href="../reference/evaluate_PR.html">evaluate_PR()</a></code>:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Obtain the predicted values for the test data with our Polynomial Regression</span>
<span class="va">n_test</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">test_y</span><span class="op">)</span>
<span class="va">prediction_PR</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">n_test</span><span class="op">)</span>

<span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">n_test</span><span class="op">)</span> <span class="op">{</span>
  <span class="va">prediction_PR</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/evaluate_PR.html">evaluate_PR</a></span><span class="op">(</span><span class="va">test</span><span class="op">[</span><span class="va">i</span>, <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="va">p</span><span class="op">)</span><span class="op">]</span>, <span class="va">coeffs</span><span class="op">)</span>
<span class="op">}</span>

<span class="co"># Obtain the predicted values with the NN to compare them</span>
<span class="va">prediction_NN</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">nn</span>, <span class="va">test_x</span><span class="op">)</span></code></pre></div>
<p>A simple plot comparing the PR and NN predictions can be obtained with <code><a href="../reference/plot_NN_PR_comparison.html">plot_NN_PR_comparison()</a></code>, where the red diagonal line represents where a perfect relationship between the NN and the PR would be obtained. In this example, as the theoretical weights constraints have not been imposed, we can observe how the approximation is not perfect:</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/plot_NN_PR_comparison.html">plot_NN_PR_comparison</a></span><span class="op">(</span><span class="va">prediction_PR</span>, <span class="va">prediction_NN</span><span class="op">)</span></code></pre></div>
<p><img src="nn2pr-01-introduction_files/figure-html/unnamed-chunk-15-1.png" width="700"></p>
<p>Finally, a convenient plot to show how the algorithm is affected by each layer can be obtained with <code><a href="../reference/plot_taylor_and_synpatic_potentials.html">plot_taylor_and_synpatic_potentials()</a></code>, where the synaptic potentials at each neuron are computed and presented over the Taylor expansion approximation of the activation function at each layer:</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/plot_taylor_and_synpatic_potentials.html">plot_taylor_and_synpatic_potentials</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">train</span>,
                                    weights_list <span class="op">=</span> <span class="va">nn_weights</span>,
                                    af_string_list <span class="op">=</span> <span class="va">af_string_list</span>,
                                    q_taylor_vector <span class="op">=</span> <span class="va">q_taylor_vector</span><span class="op">)</span>
<span class="co">#&gt; [[1]]</span></code></pre></div>
<p><img src="nn2pr-01-introduction_files/figure-html/unnamed-chunk-16-1.png" width="700"></p>
<pre><code>#&gt; 
#&gt; [[2]]</code></pre>
<p><img src="nn2pr-01-introduction_files/figure-html/unnamed-chunk-16-2.png" width="700"></p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Pablo Morala.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
